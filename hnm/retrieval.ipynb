{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17acabec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba398a",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a7b33",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 17\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = pd.read_csv('dataset/articles.csv')\n",
    "article_top_df = pd.read_csv('dataset/articles_ranked.csv')\n",
    "\n",
    "customer_df = pd.read_csv('dataset/customers.csv')\n",
    "trans_df = pd.read_csv('dataset/transactions_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6207b42b",
   "metadata": {},
   "source": [
    "#### Use only top-K articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 20000  # currently not used\n",
    "N_SAMPLES = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_top_df.head(12)['article_id'].to_list()\n",
    "percentage = article_top_df[\"transaction_counts\"][:TOP_K].sum() / article_top_df[\"transaction_counts\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261f759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Top {TOP_K} most sold H&M articles only account for {percentage:.2%} of the total (sold) articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0108641",
   "metadata": {},
   "source": [
    "#### Get random N samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = trans_df.sample(frac=1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7edf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trans_df = trans_df.head(N_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81994fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trans_df.customer_id.unique()) / 1371980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.fillna(value='', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9632e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_df['t_dat'] = pd.to_datetime(trans_df['t_dat']).values.astype(int) / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df.rename(columns={\"t_dat\":\"timestamp\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_map = dict(article_df[['article_id', 'prod_name']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df['prod_name'] = trans_df.article_id.map(article_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = tf.data.Dataset.from_tensor_slices(dict(article_df)).map(lambda x: {\n",
    "    'article_id' : tf.strings.as_string(x['article_id']),\n",
    "    'prod_name' : x['prod_name'],\n",
    "})\n",
    "\n",
    "trans = tf.data.Dataset.from_tensor_slices(dict(trans_df)).map(lambda x: {\n",
    "    'customer_id' : x['customer_id'],\n",
    "    'article_id' : tf.strings.as_string(x['article_id']),\n",
    "    'prod_name' : x['prod_name'],\n",
    "    'timestamp' : x['timestamp'],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da9b06",
   "metadata": {},
   "source": [
    "#### Features Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(trans.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE THIS TO AVOID STRINGLOOKUP\n",
    "article_ids = articles.map(lambda x: x['article_id']).batch(1_000)\n",
    "unique_article_ids = np.unique(np.concatenate(list(article_ids)))\n",
    "\n",
    "customer_ids = trans.map(lambda x: x['customer_id']).batch(1_000)\n",
    "unique_customer_ids = np.unique(np.concatenate(list(customer_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f4609",
   "metadata": {},
   "source": [
    "## Two-tower Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerModel(tf.keras.Model):\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "\n",
    "    self._use_timestamps = use_timestamps\n",
    "    \n",
    "    embedding_dim = 32\n",
    "    \n",
    "    self.user_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_customer_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_customer_ids) + 1, embedding_dim),\n",
    "    ])\n",
    "\n",
    "    if use_timestamps:\n",
    "      self.timestamp_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, embedding_dim),\n",
    "      ])\n",
    "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "          axis=None\n",
    "      )\n",
    "\n",
    "      self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    print(input)\n",
    "    if not self._use_timestamps:\n",
    "      return self.user_embedding(inputs[\"customer_id\"])\n",
    "\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"customer_id\"]),\n",
    "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f161d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "    \n",
    "    embedding_dim = 32\n",
    "\n",
    "    self.article_id_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_article_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_article_ids) + 1, embedding_dim)\n",
    "    ])\n",
    "\n",
    "    self.article_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens)\n",
    "\n",
    "    self.article_text_embedding = tf.keras.Sequential([\n",
    "      self.article_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, embedding_dim, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.article_vectorizer.adapt(articles.map(lambda x: x[\"prod_name\"]))\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.concat([\n",
    "        self.article_id_embedding(inputs[\"article_id\"]),\n",
    "        self.article_text_embedding(inputs[\"prod_name\"]),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNMModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "    self.query_model = tf.keras.Sequential([\n",
    "      CustomerModel(use_timestamps),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.candidate_model = tf.keras.Sequential([\n",
    "      ArticleModel(),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=articles.batch(128).map(self.candidate_model),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    query_embedding = self.query_model({\n",
    "        \"customer_id\": features[\"customer_id\"],\n",
    "        \"timestamp\": features[\"timestamp\"],\n",
    "    })\n",
    "    candidate_embedding = self.candidate_model({\n",
    "        \"article_id\": features[\"article_id\"],\n",
    "        \"prod_name\": features[\"prod_name\"],\n",
    "    })\n",
    "\n",
    "    return self.task(query_embedding, candidate_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf05746",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_FREQ = 1\n",
    "EPOCHS = 7\n",
    "INIT_EPOCH = 6  # set to latest epoch when resuming from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = trans.shuffle(trans_df.shape[0], seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(800_000)\n",
    "test = shuffled.skip(800_000).take(200_000)\n",
    "\n",
    "cached_train = train.shuffle(800_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53134afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/test_3/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    period=EVAL_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea8cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = HNMModel(use_timestamps=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "if INIT_EPOCH > 0:\n",
    "    # Load trained model weights\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)\n",
    "\n",
    "wo_timestamp_hist = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=EVAL_FREQ,\n",
    "    epochs=EPOCHS,\n",
    "    initial_epoch=INIT_EPOCH,\n",
    "    callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57884049",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_runs = len(wo_timestamp_hist.history[\"val_factorized_top_k/top_10_categorical_accuracy\"])\n",
    "epochs = [(x + 1)* EVAL_FREQ for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, wo_timestamp_hist.history[\"val_factorized_top_k/top_10_categorical_accuracy\"], label=\"w/o timesteps\")\n",
    "# plt.plot(epochs, w_timestamp_hist.history[\"val_factorized_top_k/top_10_categorical_accuracy\"], label=\"w/ timesteps\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfacc69",
   "metadata": {},
   "source": [
    "## Get Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ac8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.batch(100).map(lambda x: model.candidate_model({\n",
    "    'article_id': x['article_id'],\n",
    "    'prod_name' : x['prod_name'],\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6acea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
    "\n",
    "identifiers = articles.batch(100).map(lambda x: x['article_id'])\n",
    "\n",
    "candidates = articles.batch(100).map(lambda x: model.candidate_model({\n",
    "        'article_id': x['article_id'],\n",
    "        'prod_name' : x['prod_name'],\n",
    "    }))\n",
    "\n",
    "index.index_from_dataset(tf.data.Dataset.zip((identifiers, candidates)))\n",
    "\n",
    "test_query = dict(trans_df[['customer_id',\n",
    "                           'timestamp',\n",
    "                        ]].iloc[0].map(lambda x: tf.expand_dims(x, axis=0)))\n",
    "\n",
    "# test_query = {'customer_id' : tf.expand_dims('ffffd9ac14e89946416d80e791d064701994755c3ab686a1eaf3458c36f52241', axis=0)}\n",
    "\n",
    "_, titles = index(test_query, k=12)\n",
    "print(f\"Top 12 recommendations for user 40: {titles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5938e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'customer_id' : tf.expand_dims('ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38b2236865d949d4df6a', axis=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df.loc[trans_df['customer_id'] == 'ffffd9ac14e89946416d80e791d064701994755c3ab686a1eaf3458c36f52241']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_map[684080001]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
