{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17acabec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 05:55:55.800686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-21 05:55:55.800709: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba398a",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e426694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = pd.read_csv('dataset/articles.csv')\n",
    "customer_df = pd.read_csv('dataset/customers.csv')\n",
    "trans_df = pd.read_csv('dataset/transactions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af06ceb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "article_df.fillna(value='', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6265241b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3021994/846968922.py:1: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  trans_df['t_dat'] = pd.to_datetime(trans_df['t_dat']).astype(int) / 10**9\n"
     ]
    }
   ],
   "source": [
    "trans_df['t_dat'] = pd.to_datetime(trans_df['t_dat']).astype(int) / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69409ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df.customer_id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d7f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df.rename(columns={\"t_dat\":\"timestamp\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99c09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_map = dict(article_df[['article_id', 'prod_name']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d852260",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df['prod_name'] = trans_df.article_id.map(article_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aebe726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = tf.data.Dataset.from_tensor_slices(dict(article_df)).map(lambda x: tf.strings.as_string(x['article_id']))\n",
    "\n",
    "trans = tf.data.Dataset.from_tensor_slices(dict(trans_df[:1000000])).map(lambda x: {\n",
    "    'customer_id' : x['customer_id'],\n",
    "    'article_id' : tf.strings.as_string(x['article_id']),\n",
    "    'prod_name' : x['prod_name'],\n",
    "    'timestamp' : x['timestamp'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7274d5f0",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f36009",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(trans.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2570ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### USE THIS TO USE STRINGLOOKUP\n",
    "# customer_vocab = tf.keras.layers.StringLookup(mask_token=None)\n",
    "# customer_vocab.adapt(trans.map(lambda x: x[\"customer_id\"]))\n",
    "\n",
    "# article_vocab = tf.keras.layers.StringLookup(mask_token=None)\n",
    "# article_vocab.adapt(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e5aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE THIS TO AVOID STRINGLOOKUP\n",
    "article_ids = articles.batch(1_000)\n",
    "unique_article_ids = np.unique(np.concatenate(list(article_ids)))\n",
    "\n",
    "customer_ids = trans.map(lambda x: x['customer_id']).batch(1_000)\n",
    "unique_customer_ids = np.unique(np.concatenate(list(customer_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d21c007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = articles.batch(1_000)\n",
    "len(list(d.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f4609",
   "metadata": {},
   "source": [
    "## Two-tower Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16f4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### USE THIS TO USE STRINGLOOKUP\n",
    "# embedding_dim = 32\n",
    "\n",
    "# customer_model = tf.keras.Sequential([\n",
    "#     customer_vocab,\n",
    "#     tf.keras.layers.Embedding(customer_vocab.vocabulary_size(), embedding_dim)\n",
    "# ])\n",
    "# article_model = tf.keras.Sequential([\n",
    "#     article_vocab,\n",
    "#     tf.keras.layers.Embedding(article_vocab.vocabulary_size(), embedding_dim)\n",
    "# ])\n",
    "\n",
    "# task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "#     articles.batch(128).map(article_model)\n",
    "#   )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d418d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### USE THIS TO AVOID STRINGLOOKUP\n",
    "# embedding_dim = 32\n",
    "\n",
    "# customer_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.StringLookup(vocabulary=unique_customer_ids, mask_token=None),\n",
    "#     tf.keras.layers.Embedding(len(unique_customer_ids)+1, embedding_dim)\n",
    "# ])\n",
    "# article_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.StringLookup(vocabulary=unique_article_ids, mask_token=None),\n",
    "#     tf.keras.layers.Embedding(len(unique_article_ids)+1, embedding_dim)\n",
    "# ])\n",
    "\n",
    "# task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "#     articles.batch(128).map(article_model)\n",
    "#   )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c9184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerModel(tf.keras.Model):\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "\n",
    "    self._use_timestamps = use_timestamps\n",
    "    \n",
    "    embedding_dim = 32\n",
    "    \n",
    "    self.user_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_customer_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_customer_ids) + 1, embedding_dim),\n",
    "    ])\n",
    "\n",
    "    if use_timestamps:\n",
    "      self.timestamp_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, embedding_dim),\n",
    "      ])\n",
    "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "          axis=None\n",
    "      )\n",
    "\n",
    "      self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    print(input)\n",
    "    if not self._use_timestamps:\n",
    "      return self.user_embedding(inputs[\"customer_id\"])\n",
    "\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"customer_id\"]),\n",
    "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18b7b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "    \n",
    "    embedding_dim = 32\n",
    "\n",
    "    self.article_id_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_article_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_article_ids) + 1, embedding_dim)\n",
    "    ])\n",
    "\n",
    "#     self.article_vectorizer = tf.keras.layers.TextVectorization(\n",
    "#         max_tokens=max_tokens)\n",
    "\n",
    "#     self.article_text_embedding = tf.keras.Sequential([\n",
    "#       self.article_vectorizer,\n",
    "#       tf.keras.layers.Embedding(max_tokens, embedding_dim, mask_zero=True),\n",
    "#       tf.keras.layers.GlobalAveragePooling1D(),\n",
    "#     ])\n",
    "\n",
    "#     self.article_vectorizer.adapt(articles.map(lambda x: x[\"prod_name\"]))\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.concat([\n",
    "        self.article_id_embedding(inputs),\n",
    "#         self.article_text_embedding(inputs[\"prod_name\"]),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f6ad866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNMModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "    self.query_model = tf.keras.Sequential([\n",
    "      CustomerModel(use_timestamps),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.candidate_model = tf.keras.Sequential([\n",
    "      ArticleModel(),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=articles.batch(128).map(self.candidate_model),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    query_embedding = self.query_model({\n",
    "        \"customer_id\": features[\"customer_id\"],\n",
    "        \"timestamp\": features[\"timestamp\"],\n",
    "    })\n",
    "    candidate_embedding = self.candidate_model({\n",
    "        \"article_id\": features[\"article_id\"],\n",
    "#         \"prod_name\": features[\"prod_name\"],\n",
    "    })\n",
    "\n",
    "    return self.task(query_embedding, candidate_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf05746",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "824a7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = trans.shuffle(100_000, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b6ac403d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer_id': array([b'54f6d5274311ae719a4a8e7469ad5cd7a43dafc252f446332060b86c7df764d3',\n",
       "        b'ffd9c246a42bdf42c6923238d0b5e66ba157ec68c5bcc61d89f24bb466d3cddc',\n",
       "        b'1e6d960a176b9e4d9aed07387f7164845a2e2085f07f0d313602b4771b4ef4ae',\n",
       "        ...,\n",
       "        b'1e38c9a1b7cfbd093bf2719b0ff3406f57474e36dae8e471ec2a4af66675756a',\n",
       "        b'934b876b64aeb1d5a24895d1dd2e857b927d38e7a9fa9ccae4d1c9997300bb12',\n",
       "        b'a9db29ebfa809a9018169f65de70b0c515b174ac1f96ed2c7ce767eb96ea4efc'],\n",
       "       dtype=object),\n",
       " 'article_id': array([b'504152001', b'529012025', b'687427001', ..., b'355072003',\n",
       "        b'384851013', b'656031001'], dtype=object),\n",
       " 'prod_name': array([b'Friend', b'Hazelnut Brazilian Acacia Low',\n",
       "        b'Brisbane off shoulder', ..., b'Anita Tank (1)', b'Sage Shorts',\n",
       "        b'Eden Hipster Ch. Poppy Mid'], dtype=object),\n",
       " 'timestamp': array([1.5374880e+09, 1.5374016e+09, 1.5374880e+09, ..., 1.5376608e+09,\n",
       "        1.5376608e+09, 1.5374016e+09])}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cached_train.as_numpy_iterator())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25c78c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.range(100)\n",
    "ds = ds.shuffle(10)\n",
    "\n",
    "tr = ds.take(8)\n",
    "test = ds.skip(8).take(2)\n",
    "\n",
    "c_tr = tr.shuffle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b0c0c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 6, 2, 7, 5, 4, 8, 14]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c_tr.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3846c576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7fac9c42dac0>>\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7fac9c42dac0>>\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 115s 3s/step - factorized_top_k/top_1_categorical_accuracy: 9.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0069 - factorized_top_k/top_10_categorical_accuracy: 0.0114 - factorized_top_k/top_50_categorical_accuracy: 0.0296 - factorized_top_k/top_100_categorical_accuracy: 0.0441 - loss: 14852.3718 - regularization_loss: 0.0000e+00 - total_loss: 14852.3718\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0083 - factorized_top_k/top_5_categorical_accuracy: 0.0480 - factorized_top_k/top_10_categorical_accuracy: 0.0702 - factorized_top_k/top_50_categorical_accuracy: 0.1463 - factorized_top_k/top_100_categorical_accuracy: 0.1951 - loss: 13770.7926 - regularization_loss: 0.0000e+00 - total_loss: 13770.7926\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0456 - factorized_top_k/top_5_categorical_accuracy: 0.1777 - factorized_top_k/top_10_categorical_accuracy: 0.2289 - factorized_top_k/top_50_categorical_accuracy: 0.3677 - factorized_top_k/top_100_categorical_accuracy: 0.4408 - loss: 10540.9574 - regularization_loss: 0.0000e+00 - total_loss: 10540.9574\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.1069 - factorized_top_k/top_5_categorical_accuracy: 0.3046 - factorized_top_k/top_10_categorical_accuracy: 0.3697 - factorized_top_k/top_50_categorical_accuracy: 0.5440 - factorized_top_k/top_100_categorical_accuracy: 0.6277 - loss: 7573.3607 - regularization_loss: 0.0000e+00 - total_loss: 7573.3607\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - factorized_top_k/top_1_categorical_accuracy: 0.1714 - factorized_top_k/top_5_categorical_accuracy: 0.4326 - factorized_top_k/top_10_categorical_accuracy: 0.5114 - factorized_top_k/top_50_categorical_accuracy: 0.6841 - factorized_top_k/top_100_categorical_accuracy: 0.7549 - loss: 6027.3141 - regularization_loss: 0.0000e+00 - total_loss: 6027.3141WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7fac9c42dac0>>\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 146s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.1714 - factorized_top_k/top_5_categorical_accuracy: 0.4326 - factorized_top_k/top_10_categorical_accuracy: 0.5114 - factorized_top_k/top_50_categorical_accuracy: 0.6841 - factorized_top_k/top_100_categorical_accuracy: 0.7549 - loss: 5884.0639 - regularization_loss: 0.0000e+00 - total_loss: 5884.0639 - val_factorized_top_k/top_1_categorical_accuracy: 0.0195 - val_factorized_top_k/top_5_categorical_accuracy: 0.0451 - val_factorized_top_k/top_10_categorical_accuracy: 0.0526 - val_factorized_top_k/top_50_categorical_accuracy: 0.0763 - val_factorized_top_k/top_100_categorical_accuracy: 0.0890 - val_loss: 38992.0234 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38992.0234\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2053 - factorized_top_k/top_5_categorical_accuracy: 0.4953 - factorized_top_k/top_10_categorical_accuracy: 0.5859 - factorized_top_k/top_50_categorical_accuracy: 0.7637 - factorized_top_k/top_100_categorical_accuracy: 0.8269 - loss: 5027.5046 - regularization_loss: 0.0000e+00 - total_loss: 5027.5046\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2210 - factorized_top_k/top_5_categorical_accuracy: 0.5555 - factorized_top_k/top_10_categorical_accuracy: 0.6533 - factorized_top_k/top_50_categorical_accuracy: 0.8179 - factorized_top_k/top_100_categorical_accuracy: 0.8706 - loss: 4449.5502 - regularization_loss: 0.0000e+00 - total_loss: 4449.5502\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2347 - factorized_top_k/top_5_categorical_accuracy: 0.5993 - factorized_top_k/top_10_categorical_accuracy: 0.6990 - factorized_top_k/top_50_categorical_accuracy: 0.8560 - factorized_top_k/top_100_categorical_accuracy: 0.9002 - loss: 4049.9555 - regularization_loss: 0.0000e+00 - total_loss: 4049.9555\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2396 - factorized_top_k/top_5_categorical_accuracy: 0.6304 - factorized_top_k/top_10_categorical_accuracy: 0.7328 - factorized_top_k/top_50_categorical_accuracy: 0.8814 - factorized_top_k/top_100_categorical_accuracy: 0.9203 - loss: 3762.6405 - regularization_loss: 0.0000e+00 - total_loss: 3762.6405\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2440 - factorized_top_k/top_5_categorical_accuracy: 0.6543 - factorized_top_k/top_10_categorical_accuracy: 0.7599 - factorized_top_k/top_50_categorical_accuracy: 0.9006 - factorized_top_k/top_100_categorical_accuracy: 0.9340 - loss: 3550.6189 - regularization_loss: 0.0000e+00 - total_loss: 3550.6189 - val_factorized_top_k/top_1_categorical_accuracy: 0.0230 - val_factorized_top_k/top_5_categorical_accuracy: 0.0604 - val_factorized_top_k/top_10_categorical_accuracy: 0.0715 - val_factorized_top_k/top_50_categorical_accuracy: 0.0974 - val_factorized_top_k/top_100_categorical_accuracy: 0.1124 - val_loss: 45412.0469 - val_regularization_loss: 0.0000e+00 - val_total_loss: 45412.0469\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2476 - factorized_top_k/top_5_categorical_accuracy: 0.6738 - factorized_top_k/top_10_categorical_accuracy: 0.7809 - factorized_top_k/top_50_categorical_accuracy: 0.9156 - factorized_top_k/top_100_categorical_accuracy: 0.9450 - loss: 3383.3077 - regularization_loss: 0.0000e+00 - total_loss: 3383.3077\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2504 - factorized_top_k/top_5_categorical_accuracy: 0.6896 - factorized_top_k/top_10_categorical_accuracy: 0.7980 - factorized_top_k/top_50_categorical_accuracy: 0.9273 - factorized_top_k/top_100_categorical_accuracy: 0.9526 - loss: 3243.4138 - regularization_loss: 0.0000e+00 - total_loss: 3243.4138\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2531 - factorized_top_k/top_5_categorical_accuracy: 0.7045 - factorized_top_k/top_10_categorical_accuracy: 0.8140 - factorized_top_k/top_50_categorical_accuracy: 0.9351 - factorized_top_k/top_100_categorical_accuracy: 0.9587 - loss: 3128.8672 - regularization_loss: 0.0000e+00 - total_loss: 3128.8672\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2558 - factorized_top_k/top_5_categorical_accuracy: 0.7135 - factorized_top_k/top_10_categorical_accuracy: 0.8246 - factorized_top_k/top_50_categorical_accuracy: 0.9419 - factorized_top_k/top_100_categorical_accuracy: 0.9635 - loss: 3036.8279 - regularization_loss: 0.0000e+00 - total_loss: 3036.8279\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2551 - factorized_top_k/top_5_categorical_accuracy: 0.7242 - factorized_top_k/top_10_categorical_accuracy: 0.8372 - factorized_top_k/top_50_categorical_accuracy: 0.9479 - factorized_top_k/top_100_categorical_accuracy: 0.9674 - loss: 2947.5009 - regularization_loss: 0.0000e+00 - total_loss: 2947.5009 - val_factorized_top_k/top_1_categorical_accuracy: 0.0226 - val_factorized_top_k/top_5_categorical_accuracy: 0.0663 - val_factorized_top_k/top_10_categorical_accuracy: 0.0780 - val_factorized_top_k/top_50_categorical_accuracy: 0.1024 - val_factorized_top_k/top_100_categorical_accuracy: 0.1207 - val_loss: 48947.1250 - val_regularization_loss: 0.0000e+00 - val_total_loss: 48947.1250\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2552 - factorized_top_k/top_5_categorical_accuracy: 0.7353 - factorized_top_k/top_10_categorical_accuracy: 0.8476 - factorized_top_k/top_50_categorical_accuracy: 0.9526 - factorized_top_k/top_100_categorical_accuracy: 0.9709 - loss: 2876.1551 - regularization_loss: 0.0000e+00 - total_loss: 2876.1551\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2567 - factorized_top_k/top_5_categorical_accuracy: 0.7436 - factorized_top_k/top_10_categorical_accuracy: 0.8569 - factorized_top_k/top_50_categorical_accuracy: 0.9570 - factorized_top_k/top_100_categorical_accuracy: 0.9734 - loss: 2808.5602 - regularization_loss: 0.0000e+00 - total_loss: 2808.5602\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2594 - factorized_top_k/top_5_categorical_accuracy: 0.7528 - factorized_top_k/top_10_categorical_accuracy: 0.8638 - factorized_top_k/top_50_categorical_accuracy: 0.9609 - factorized_top_k/top_100_categorical_accuracy: 0.9761 - loss: 2748.5287 - regularization_loss: 0.0000e+00 - total_loss: 2748.5287\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2593 - factorized_top_k/top_5_categorical_accuracy: 0.7595 - factorized_top_k/top_10_categorical_accuracy: 0.8733 - factorized_top_k/top_50_categorical_accuracy: 0.9643 - factorized_top_k/top_100_categorical_accuracy: 0.9785 - loss: 2683.3329 - regularization_loss: 0.0000e+00 - total_loss: 2683.3329\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2602 - factorized_top_k/top_5_categorical_accuracy: 0.7661 - factorized_top_k/top_10_categorical_accuracy: 0.8785 - factorized_top_k/top_50_categorical_accuracy: 0.9674 - factorized_top_k/top_100_categorical_accuracy: 0.9802 - loss: 2643.1501 - regularization_loss: 0.0000e+00 - total_loss: 2643.1501 - val_factorized_top_k/top_1_categorical_accuracy: 0.0246 - val_factorized_top_k/top_5_categorical_accuracy: 0.0703 - val_factorized_top_k/top_10_categorical_accuracy: 0.0825 - val_factorized_top_k/top_50_categorical_accuracy: 0.1069 - val_factorized_top_k/top_100_categorical_accuracy: 0.1247 - val_loss: 51123.5625 - val_regularization_loss: 0.0000e+00 - val_total_loss: 51123.5625\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2591 - factorized_top_k/top_5_categorical_accuracy: 0.7722 - factorized_top_k/top_10_categorical_accuracy: 0.8847 - factorized_top_k/top_50_categorical_accuracy: 0.9701 - factorized_top_k/top_100_categorical_accuracy: 0.9822 - loss: 2596.9853 - regularization_loss: 0.0000e+00 - total_loss: 2596.9853\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2596 - factorized_top_k/top_5_categorical_accuracy: 0.7790 - factorized_top_k/top_10_categorical_accuracy: 0.8910 - factorized_top_k/top_50_categorical_accuracy: 0.9722 - factorized_top_k/top_100_categorical_accuracy: 0.9835 - loss: 2560.4313 - regularization_loss: 0.0000e+00 - total_loss: 2560.4313\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2599 - factorized_top_k/top_5_categorical_accuracy: 0.7834 - factorized_top_k/top_10_categorical_accuracy: 0.8957 - factorized_top_k/top_50_categorical_accuracy: 0.9743 - factorized_top_k/top_100_categorical_accuracy: 0.9851 - loss: 2518.5311 - regularization_loss: 0.0000e+00 - total_loss: 2518.5311\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2586 - factorized_top_k/top_5_categorical_accuracy: 0.7879 - factorized_top_k/top_10_categorical_accuracy: 0.9012 - factorized_top_k/top_50_categorical_accuracy: 0.9760 - factorized_top_k/top_100_categorical_accuracy: 0.9862 - loss: 2484.7277 - regularization_loss: 0.0000e+00 - total_loss: 2484.7277\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2602 - factorized_top_k/top_5_categorical_accuracy: 0.7925 - factorized_top_k/top_10_categorical_accuracy: 0.9045 - factorized_top_k/top_50_categorical_accuracy: 0.9782 - factorized_top_k/top_100_categorical_accuracy: 0.9873 - loss: 2447.5593 - regularization_loss: 0.0000e+00 - total_loss: 2447.5593 - val_factorized_top_k/top_1_categorical_accuracy: 0.0220 - val_factorized_top_k/top_5_categorical_accuracy: 0.0710 - val_factorized_top_k/top_10_categorical_accuracy: 0.0832 - val_factorized_top_k/top_50_categorical_accuracy: 0.1093 - val_factorized_top_k/top_100_categorical_accuracy: 0.1273 - val_loss: 52468.8125 - val_regularization_loss: 0.0000e+00 - val_total_loss: 52468.8125\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2602 - factorized_top_k/top_5_categorical_accuracy: 0.7983 - factorized_top_k/top_10_categorical_accuracy: 0.9101 - factorized_top_k/top_50_categorical_accuracy: 0.9796 - factorized_top_k/top_100_categorical_accuracy: 0.9883 - loss: 2426.1206 - regularization_loss: 0.0000e+00 - total_loss: 2426.1206\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2593 - factorized_top_k/top_5_categorical_accuracy: 0.8014 - factorized_top_k/top_10_categorical_accuracy: 0.9128 - factorized_top_k/top_50_categorical_accuracy: 0.9808 - factorized_top_k/top_100_categorical_accuracy: 0.9892 - loss: 2393.6310 - regularization_loss: 0.0000e+00 - total_loss: 2393.6310\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2612 - factorized_top_k/top_5_categorical_accuracy: 0.8031 - factorized_top_k/top_10_categorical_accuracy: 0.9162 - factorized_top_k/top_50_categorical_accuracy: 0.9825 - factorized_top_k/top_100_categorical_accuracy: 0.9899 - loss: 2367.3844 - regularization_loss: 0.0000e+00 - total_loss: 2367.3844\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 117s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2596 - factorized_top_k/top_5_categorical_accuracy: 0.8066 - factorized_top_k/top_10_categorical_accuracy: 0.9195 - factorized_top_k/top_50_categorical_accuracy: 0.9834 - factorized_top_k/top_100_categorical_accuracy: 0.9908 - loss: 2339.7570 - regularization_loss: 0.0000e+00 - total_loss: 2339.7570\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2613 - factorized_top_k/top_5_categorical_accuracy: 0.8111 - factorized_top_k/top_10_categorical_accuracy: 0.9228 - factorized_top_k/top_50_categorical_accuracy: 0.9847 - factorized_top_k/top_100_categorical_accuracy: 0.9914 - loss: 2319.3726 - regularization_loss: 0.0000e+00 - total_loss: 2319.3726 - val_factorized_top_k/top_1_categorical_accuracy: 0.0230 - val_factorized_top_k/top_5_categorical_accuracy: 0.0728 - val_factorized_top_k/top_10_categorical_accuracy: 0.0845 - val_factorized_top_k/top_50_categorical_accuracy: 0.1110 - val_factorized_top_k/top_100_categorical_accuracy: 0.1293 - val_loss: 53449.5156 - val_regularization_loss: 0.0000e+00 - val_total_loss: 53449.5156\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2580 - factorized_top_k/top_5_categorical_accuracy: 0.8142 - factorized_top_k/top_10_categorical_accuracy: 0.9253 - factorized_top_k/top_50_categorical_accuracy: 0.9855 - factorized_top_k/top_100_categorical_accuracy: 0.9918 - loss: 2299.9713 - regularization_loss: 0.0000e+00 - total_loss: 2299.9713\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2591 - factorized_top_k/top_5_categorical_accuracy: 0.8170 - factorized_top_k/top_10_categorical_accuracy: 0.9271 - factorized_top_k/top_50_categorical_accuracy: 0.9862 - factorized_top_k/top_100_categorical_accuracy: 0.9923 - loss: 2271.8032 - regularization_loss: 0.0000e+00 - total_loss: 2271.8032\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2578 - factorized_top_k/top_5_categorical_accuracy: 0.8182 - factorized_top_k/top_10_categorical_accuracy: 0.9309 - factorized_top_k/top_50_categorical_accuracy: 0.9872 - factorized_top_k/top_100_categorical_accuracy: 0.9926 - loss: 2271.5272 - regularization_loss: 0.0000e+00 - total_loss: 2271.5272\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2575 - factorized_top_k/top_5_categorical_accuracy: 0.8208 - factorized_top_k/top_10_categorical_accuracy: 0.9323 - factorized_top_k/top_50_categorical_accuracy: 0.9879 - factorized_top_k/top_100_categorical_accuracy: 0.9932 - loss: 2243.6218 - regularization_loss: 0.0000e+00 - total_loss: 2243.6218\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2575 - factorized_top_k/top_5_categorical_accuracy: 0.8231 - factorized_top_k/top_10_categorical_accuracy: 0.9347 - factorized_top_k/top_50_categorical_accuracy: 0.9883 - factorized_top_k/top_100_categorical_accuracy: 0.9936 - loss: 2233.3865 - regularization_loss: 0.0000e+00 - total_loss: 2233.3865 - val_factorized_top_k/top_1_categorical_accuracy: 0.0215 - val_factorized_top_k/top_5_categorical_accuracy: 0.0740 - val_factorized_top_k/top_10_categorical_accuracy: 0.0859 - val_factorized_top_k/top_50_categorical_accuracy: 0.1125 - val_factorized_top_k/top_100_categorical_accuracy: 0.1299 - val_loss: 54073.3047 - val_regularization_loss: 0.0000e+00 - val_total_loss: 54073.3047\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2583 - factorized_top_k/top_5_categorical_accuracy: 0.8258 - factorized_top_k/top_10_categorical_accuracy: 0.9358 - factorized_top_k/top_50_categorical_accuracy: 0.9891 - factorized_top_k/top_100_categorical_accuracy: 0.9941 - loss: 2219.7292 - regularization_loss: 0.0000e+00 - total_loss: 2219.7292\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2555 - factorized_top_k/top_5_categorical_accuracy: 0.8276 - factorized_top_k/top_10_categorical_accuracy: 0.9388 - factorized_top_k/top_50_categorical_accuracy: 0.9895 - factorized_top_k/top_100_categorical_accuracy: 0.9945 - loss: 2196.4419 - regularization_loss: 0.0000e+00 - total_loss: 2196.4419\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2573 - factorized_top_k/top_5_categorical_accuracy: 0.8293 - factorized_top_k/top_10_categorical_accuracy: 0.9397 - factorized_top_k/top_50_categorical_accuracy: 0.9903 - factorized_top_k/top_100_categorical_accuracy: 0.9947 - loss: 2180.6242 - regularization_loss: 0.0000e+00 - total_loss: 2180.6242\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2572 - factorized_top_k/top_5_categorical_accuracy: 0.8317 - factorized_top_k/top_10_categorical_accuracy: 0.9414 - factorized_top_k/top_50_categorical_accuracy: 0.9906 - factorized_top_k/top_100_categorical_accuracy: 0.9948 - loss: 2166.1277 - regularization_loss: 0.0000e+00 - total_loss: 2166.1277\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 143s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2573 - factorized_top_k/top_5_categorical_accuracy: 0.8343 - factorized_top_k/top_10_categorical_accuracy: 0.9437 - factorized_top_k/top_50_categorical_accuracy: 0.9914 - factorized_top_k/top_100_categorical_accuracy: 0.9952 - loss: 2159.7445 - regularization_loss: 0.0000e+00 - total_loss: 2159.7445 - val_factorized_top_k/top_1_categorical_accuracy: 0.0236 - val_factorized_top_k/top_5_categorical_accuracy: 0.0757 - val_factorized_top_k/top_10_categorical_accuracy: 0.0865 - val_factorized_top_k/top_50_categorical_accuracy: 0.1130 - val_factorized_top_k/top_100_categorical_accuracy: 0.1306 - val_loss: 54666.1172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 54666.1172\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2551 - factorized_top_k/top_5_categorical_accuracy: 0.8348 - factorized_top_k/top_10_categorical_accuracy: 0.9447 - factorized_top_k/top_50_categorical_accuracy: 0.9915 - factorized_top_k/top_100_categorical_accuracy: 0.9955 - loss: 2143.8793 - regularization_loss: 0.0000e+00 - total_loss: 2143.8793\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2542 - factorized_top_k/top_5_categorical_accuracy: 0.8361 - factorized_top_k/top_10_categorical_accuracy: 0.9455 - factorized_top_k/top_50_categorical_accuracy: 0.9922 - factorized_top_k/top_100_categorical_accuracy: 0.9957 - loss: 2123.9676 - regularization_loss: 0.0000e+00 - total_loss: 2123.9676\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2552 - factorized_top_k/top_5_categorical_accuracy: 0.8383 - factorized_top_k/top_10_categorical_accuracy: 0.9468 - factorized_top_k/top_50_categorical_accuracy: 0.9923 - factorized_top_k/top_100_categorical_accuracy: 0.9959 - loss: 2121.6453 - regularization_loss: 0.0000e+00 - total_loss: 2121.6453\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2531 - factorized_top_k/top_5_categorical_accuracy: 0.8389 - factorized_top_k/top_10_categorical_accuracy: 0.9484 - factorized_top_k/top_50_categorical_accuracy: 0.9924 - factorized_top_k/top_100_categorical_accuracy: 0.9962 - loss: 2107.2662 - regularization_loss: 0.0000e+00 - total_loss: 2107.2662\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2561 - factorized_top_k/top_5_categorical_accuracy: 0.8395 - factorized_top_k/top_10_categorical_accuracy: 0.9493 - factorized_top_k/top_50_categorical_accuracy: 0.9930 - factorized_top_k/top_100_categorical_accuracy: 0.9963 - loss: 2095.1410 - regularization_loss: 0.0000e+00 - total_loss: 2095.1410 - val_factorized_top_k/top_1_categorical_accuracy: 0.0238 - val_factorized_top_k/top_5_categorical_accuracy: 0.0750 - val_factorized_top_k/top_10_categorical_accuracy: 0.0870 - val_factorized_top_k/top_50_categorical_accuracy: 0.1142 - val_factorized_top_k/top_100_categorical_accuracy: 0.1322 - val_loss: 55184.2188 - val_regularization_loss: 0.0000e+00 - val_total_loss: 55184.2188\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2555 - factorized_top_k/top_5_categorical_accuracy: 0.8415 - factorized_top_k/top_10_categorical_accuracy: 0.9501 - factorized_top_k/top_50_categorical_accuracy: 0.9935 - factorized_top_k/top_100_categorical_accuracy: 0.9964 - loss: 2095.4533 - regularization_loss: 0.0000e+00 - total_loss: 2095.4533\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2531 - factorized_top_k/top_5_categorical_accuracy: 0.8420 - factorized_top_k/top_10_categorical_accuracy: 0.9513 - factorized_top_k/top_50_categorical_accuracy: 0.9935 - factorized_top_k/top_100_categorical_accuracy: 0.9967 - loss: 2080.1052 - regularization_loss: 0.0000e+00 - total_loss: 2080.1052\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2533 - factorized_top_k/top_5_categorical_accuracy: 0.8440 - factorized_top_k/top_10_categorical_accuracy: 0.9529 - factorized_top_k/top_50_categorical_accuracy: 0.9939 - factorized_top_k/top_100_categorical_accuracy: 0.9967 - loss: 2064.1574 - regularization_loss: 0.0000e+00 - total_loss: 2064.1574\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2531 - factorized_top_k/top_5_categorical_accuracy: 0.8451 - factorized_top_k/top_10_categorical_accuracy: 0.9534 - factorized_top_k/top_50_categorical_accuracy: 0.9941 - factorized_top_k/top_100_categorical_accuracy: 0.9969 - loss: 2057.0137 - regularization_loss: 0.0000e+00 - total_loss: 2057.0137\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2504 - factorized_top_k/top_5_categorical_accuracy: 0.8452 - factorized_top_k/top_10_categorical_accuracy: 0.9536 - factorized_top_k/top_50_categorical_accuracy: 0.9943 - factorized_top_k/top_100_categorical_accuracy: 0.9971 - loss: 2045.6733 - regularization_loss: 0.0000e+00 - total_loss: 2045.6733 - val_factorized_top_k/top_1_categorical_accuracy: 0.0229 - val_factorized_top_k/top_5_categorical_accuracy: 0.0755 - val_factorized_top_k/top_10_categorical_accuracy: 0.0875 - val_factorized_top_k/top_50_categorical_accuracy: 0.1141 - val_factorized_top_k/top_100_categorical_accuracy: 0.1320 - val_loss: 55617.0508 - val_regularization_loss: 0.0000e+00 - val_total_loss: 55617.0508\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2517 - factorized_top_k/top_5_categorical_accuracy: 0.8461 - factorized_top_k/top_10_categorical_accuracy: 0.9549 - factorized_top_k/top_50_categorical_accuracy: 0.9947 - factorized_top_k/top_100_categorical_accuracy: 0.9972 - loss: 2040.4468 - regularization_loss: 0.0000e+00 - total_loss: 2040.4468\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2512 - factorized_top_k/top_5_categorical_accuracy: 0.8464 - factorized_top_k/top_10_categorical_accuracy: 0.9558 - factorized_top_k/top_50_categorical_accuracy: 0.9949 - factorized_top_k/top_100_categorical_accuracy: 0.9975 - loss: 2037.8718 - regularization_loss: 0.0000e+00 - total_loss: 2037.8718\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2505 - factorized_top_k/top_5_categorical_accuracy: 0.8491 - factorized_top_k/top_10_categorical_accuracy: 0.9553 - factorized_top_k/top_50_categorical_accuracy: 0.9951 - factorized_top_k/top_100_categorical_accuracy: 0.9975 - loss: 2030.1209 - regularization_loss: 0.0000e+00 - total_loss: 2030.1209\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2520 - factorized_top_k/top_5_categorical_accuracy: 0.8489 - factorized_top_k/top_10_categorical_accuracy: 0.9571 - factorized_top_k/top_50_categorical_accuracy: 0.9951 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 2015.9843 - regularization_loss: 0.0000e+00 - total_loss: 2015.9843\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2513 - factorized_top_k/top_5_categorical_accuracy: 0.8491 - factorized_top_k/top_10_categorical_accuracy: 0.9574 - factorized_top_k/top_50_categorical_accuracy: 0.9954 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 2017.9900 - regularization_loss: 0.0000e+00 - total_loss: 2017.9900 - val_factorized_top_k/top_1_categorical_accuracy: 0.0226 - val_factorized_top_k/top_5_categorical_accuracy: 0.0760 - val_factorized_top_k/top_10_categorical_accuracy: 0.0884 - val_factorized_top_k/top_50_categorical_accuracy: 0.1148 - val_factorized_top_k/top_100_categorical_accuracy: 0.1325 - val_loss: 55910.9766 - val_regularization_loss: 0.0000e+00 - val_total_loss: 55910.9766\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2501 - factorized_top_k/top_5_categorical_accuracy: 0.8505 - factorized_top_k/top_10_categorical_accuracy: 0.9585 - factorized_top_k/top_50_categorical_accuracy: 0.9958 - factorized_top_k/top_100_categorical_accuracy: 0.9979 - loss: 2001.4889 - regularization_loss: 0.0000e+00 - total_loss: 2001.4889\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2505 - factorized_top_k/top_5_categorical_accuracy: 0.8512 - factorized_top_k/top_10_categorical_accuracy: 0.9596 - factorized_top_k/top_50_categorical_accuracy: 0.9958 - factorized_top_k/top_100_categorical_accuracy: 0.9979 - loss: 1994.1403 - regularization_loss: 0.0000e+00 - total_loss: 1994.1403\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2494 - factorized_top_k/top_5_categorical_accuracy: 0.8521 - factorized_top_k/top_10_categorical_accuracy: 0.9596 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9980 - loss: 1996.2916 - regularization_loss: 0.0000e+00 - total_loss: 1996.2916\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2526 - factorized_top_k/top_5_categorical_accuracy: 0.8509 - factorized_top_k/top_10_categorical_accuracy: 0.9600 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9980 - loss: 1987.1449 - regularization_loss: 0.0000e+00 - total_loss: 1987.1449\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2504 - factorized_top_k/top_5_categorical_accuracy: 0.8533 - factorized_top_k/top_10_categorical_accuracy: 0.9610 - factorized_top_k/top_50_categorical_accuracy: 0.9963 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - loss: 1985.5686 - regularization_loss: 0.0000e+00 - total_loss: 1985.5686 - val_factorized_top_k/top_1_categorical_accuracy: 0.0236 - val_factorized_top_k/top_5_categorical_accuracy: 0.0765 - val_factorized_top_k/top_10_categorical_accuracy: 0.0886 - val_factorized_top_k/top_50_categorical_accuracy: 0.1153 - val_factorized_top_k/top_100_categorical_accuracy: 0.1329 - val_loss: 56181.2461 - val_regularization_loss: 0.0000e+00 - val_total_loss: 56181.2461\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2497 - factorized_top_k/top_5_categorical_accuracy: 0.8535 - factorized_top_k/top_10_categorical_accuracy: 0.9611 - factorized_top_k/top_50_categorical_accuracy: 0.9964 - factorized_top_k/top_100_categorical_accuracy: 0.9981 - loss: 1977.6206 - regularization_loss: 0.0000e+00 - total_loss: 1977.6206\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2490 - factorized_top_k/top_5_categorical_accuracy: 0.8555 - factorized_top_k/top_10_categorical_accuracy: 0.9623 - factorized_top_k/top_50_categorical_accuracy: 0.9966 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 1973.9487 - regularization_loss: 0.0000e+00 - total_loss: 1973.9487\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2490 - factorized_top_k/top_5_categorical_accuracy: 0.8544 - factorized_top_k/top_10_categorical_accuracy: 0.9627 - factorized_top_k/top_50_categorical_accuracy: 0.9966 - factorized_top_k/top_100_categorical_accuracy: 0.9983 - loss: 1961.3611 - regularization_loss: 0.0000e+00 - total_loss: 1961.3611\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2486 - factorized_top_k/top_5_categorical_accuracy: 0.8547 - factorized_top_k/top_10_categorical_accuracy: 0.9628 - factorized_top_k/top_50_categorical_accuracy: 0.9968 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 1957.8907 - regularization_loss: 0.0000e+00 - total_loss: 1957.8907\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2499 - factorized_top_k/top_5_categorical_accuracy: 0.8554 - factorized_top_k/top_10_categorical_accuracy: 0.9630 - factorized_top_k/top_50_categorical_accuracy: 0.9969 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 1949.1098 - regularization_loss: 0.0000e+00 - total_loss: 1949.1098 - val_factorized_top_k/top_1_categorical_accuracy: 0.0226 - val_factorized_top_k/top_5_categorical_accuracy: 0.0765 - val_factorized_top_k/top_10_categorical_accuracy: 0.0889 - val_factorized_top_k/top_50_categorical_accuracy: 0.1150 - val_factorized_top_k/top_100_categorical_accuracy: 0.1330 - val_loss: 56535.8125 - val_regularization_loss: 0.0000e+00 - val_total_loss: 56535.8125\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2486 - factorized_top_k/top_5_categorical_accuracy: 0.8550 - factorized_top_k/top_10_categorical_accuracy: 0.9636 - factorized_top_k/top_50_categorical_accuracy: 0.9971 - factorized_top_k/top_100_categorical_accuracy: 0.9985 - loss: 1943.2852 - regularization_loss: 0.0000e+00 - total_loss: 1943.2852\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2466 - factorized_top_k/top_5_categorical_accuracy: 0.8563 - factorized_top_k/top_10_categorical_accuracy: 0.9643 - factorized_top_k/top_50_categorical_accuracy: 0.9972 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 1952.4001 - regularization_loss: 0.0000e+00 - total_loss: 1952.4001\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2491 - factorized_top_k/top_5_categorical_accuracy: 0.8575 - factorized_top_k/top_10_categorical_accuracy: 0.9646 - factorized_top_k/top_50_categorical_accuracy: 0.9972 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 1940.6701 - regularization_loss: 0.0000e+00 - total_loss: 1940.6701\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2457 - factorized_top_k/top_5_categorical_accuracy: 0.8566 - factorized_top_k/top_10_categorical_accuracy: 0.9653 - factorized_top_k/top_50_categorical_accuracy: 0.9975 - factorized_top_k/top_100_categorical_accuracy: 0.9987 - loss: 1922.6889 - regularization_loss: 0.0000e+00 - total_loss: 1922.6889\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2503 - factorized_top_k/top_5_categorical_accuracy: 0.8576 - factorized_top_k/top_10_categorical_accuracy: 0.9650 - factorized_top_k/top_50_categorical_accuracy: 0.9974 - factorized_top_k/top_100_categorical_accuracy: 0.9987 - loss: 1932.1709 - regularization_loss: 0.0000e+00 - total_loss: 1932.1709 - val_factorized_top_k/top_1_categorical_accuracy: 0.0236 - val_factorized_top_k/top_5_categorical_accuracy: 0.0764 - val_factorized_top_k/top_10_categorical_accuracy: 0.0891 - val_factorized_top_k/top_50_categorical_accuracy: 0.1157 - val_factorized_top_k/top_100_categorical_accuracy: 0.1333 - val_loss: 56653.1680 - val_regularization_loss: 0.0000e+00 - val_total_loss: 56653.1680\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2479 - factorized_top_k/top_5_categorical_accuracy: 0.8572 - factorized_top_k/top_10_categorical_accuracy: 0.9653 - factorized_top_k/top_50_categorical_accuracy: 0.9976 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 1915.9745 - regularization_loss: 0.0000e+00 - total_loss: 1915.9745\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2464 - factorized_top_k/top_5_categorical_accuracy: 0.8586 - factorized_top_k/top_10_categorical_accuracy: 0.9661 - factorized_top_k/top_50_categorical_accuracy: 0.9977 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 1925.3195 - regularization_loss: 0.0000e+00 - total_loss: 1925.3195\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2474 - factorized_top_k/top_5_categorical_accuracy: 0.8580 - factorized_top_k/top_10_categorical_accuracy: 0.9665 - factorized_top_k/top_50_categorical_accuracy: 0.9978 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 1908.8322 - regularization_loss: 0.0000e+00 - total_loss: 1908.8322\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2451 - factorized_top_k/top_5_categorical_accuracy: 0.8587 - factorized_top_k/top_10_categorical_accuracy: 0.9665 - factorized_top_k/top_50_categorical_accuracy: 0.9978 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 1910.6930 - regularization_loss: 0.0000e+00 - total_loss: 1910.6930\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2456 - factorized_top_k/top_5_categorical_accuracy: 0.8604 - factorized_top_k/top_10_categorical_accuracy: 0.9671 - factorized_top_k/top_50_categorical_accuracy: 0.9977 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 1900.5534 - regularization_loss: 0.0000e+00 - total_loss: 1900.5534 - val_factorized_top_k/top_1_categorical_accuracy: 0.0237 - val_factorized_top_k/top_5_categorical_accuracy: 0.0760 - val_factorized_top_k/top_10_categorical_accuracy: 0.0893 - val_factorized_top_k/top_50_categorical_accuracy: 0.1152 - val_factorized_top_k/top_100_categorical_accuracy: 0.1331 - val_loss: 56783.8867 - val_regularization_loss: 0.0000e+00 - val_total_loss: 56783.8867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2455 - factorized_top_k/top_5_categorical_accuracy: 0.8601 - factorized_top_k/top_10_categorical_accuracy: 0.9671 - factorized_top_k/top_50_categorical_accuracy: 0.9980 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 1897.9272 - regularization_loss: 0.0000e+00 - total_loss: 1897.9272\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2456 - factorized_top_k/top_5_categorical_accuracy: 0.8603 - factorized_top_k/top_10_categorical_accuracy: 0.9674 - factorized_top_k/top_50_categorical_accuracy: 0.9980 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 1891.3040 - regularization_loss: 0.0000e+00 - total_loss: 1891.3040\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2453 - factorized_top_k/top_5_categorical_accuracy: 0.8609 - factorized_top_k/top_10_categorical_accuracy: 0.9679 - factorized_top_k/top_50_categorical_accuracy: 0.9980 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1892.2469 - regularization_loss: 0.0000e+00 - total_loss: 1892.2469\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2449 - factorized_top_k/top_5_categorical_accuracy: 0.8605 - factorized_top_k/top_10_categorical_accuracy: 0.9680 - factorized_top_k/top_50_categorical_accuracy: 0.9981 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1881.6329 - regularization_loss: 0.0000e+00 - total_loss: 1881.6329\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2450 - factorized_top_k/top_5_categorical_accuracy: 0.8608 - factorized_top_k/top_10_categorical_accuracy: 0.9683 - factorized_top_k/top_50_categorical_accuracy: 0.9982 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1888.2371 - regularization_loss: 0.0000e+00 - total_loss: 1888.2371 - val_factorized_top_k/top_1_categorical_accuracy: 0.0231 - val_factorized_top_k/top_5_categorical_accuracy: 0.0765 - val_factorized_top_k/top_10_categorical_accuracy: 0.0894 - val_factorized_top_k/top_50_categorical_accuracy: 0.1155 - val_factorized_top_k/top_100_categorical_accuracy: 0.1332 - val_loss: 56929.5781 - val_regularization_loss: 0.0000e+00 - val_total_loss: 56929.5781\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2462 - factorized_top_k/top_5_categorical_accuracy: 0.8613 - factorized_top_k/top_10_categorical_accuracy: 0.9685 - factorized_top_k/top_50_categorical_accuracy: 0.9983 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1888.9058 - regularization_loss: 0.0000e+00 - total_loss: 1888.9058\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2446 - factorized_top_k/top_5_categorical_accuracy: 0.8615 - factorized_top_k/top_10_categorical_accuracy: 0.9689 - factorized_top_k/top_50_categorical_accuracy: 0.9983 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1882.7629 - regularization_loss: 0.0000e+00 - total_loss: 1882.7629\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2437 - factorized_top_k/top_5_categorical_accuracy: 0.8617 - factorized_top_k/top_10_categorical_accuracy: 0.9692 - factorized_top_k/top_50_categorical_accuracy: 0.9984 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1870.3656 - regularization_loss: 0.0000e+00 - total_loss: 1870.3656\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2448 - factorized_top_k/top_5_categorical_accuracy: 0.8615 - factorized_top_k/top_10_categorical_accuracy: 0.9688 - factorized_top_k/top_50_categorical_accuracy: 0.9983 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1859.6551 - regularization_loss: 0.0000e+00 - total_loss: 1859.6551\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 139s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2447 - factorized_top_k/top_5_categorical_accuracy: 0.8621 - factorized_top_k/top_10_categorical_accuracy: 0.9697 - factorized_top_k/top_50_categorical_accuracy: 0.9984 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 1868.1462 - regularization_loss: 0.0000e+00 - total_loss: 1868.1462 - val_factorized_top_k/top_1_categorical_accuracy: 0.0220 - val_factorized_top_k/top_5_categorical_accuracy: 0.0768 - val_factorized_top_k/top_10_categorical_accuracy: 0.0896 - val_factorized_top_k/top_50_categorical_accuracy: 0.1160 - val_factorized_top_k/top_100_categorical_accuracy: 0.1330 - val_loss: 57125.9180 - val_regularization_loss: 0.0000e+00 - val_total_loss: 57125.9180\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2444 - factorized_top_k/top_5_categorical_accuracy: 0.8626 - factorized_top_k/top_10_categorical_accuracy: 0.9703 - factorized_top_k/top_50_categorical_accuracy: 0.9985 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 1856.5488 - regularization_loss: 0.0000e+00 - total_loss: 1856.5488\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2449 - factorized_top_k/top_5_categorical_accuracy: 0.8637 - factorized_top_k/top_10_categorical_accuracy: 0.9702 - factorized_top_k/top_50_categorical_accuracy: 0.9985 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 1860.6615 - regularization_loss: 0.0000e+00 - total_loss: 1860.6615\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2437 - factorized_top_k/top_5_categorical_accuracy: 0.8634 - factorized_top_k/top_10_categorical_accuracy: 0.9704 - factorized_top_k/top_50_categorical_accuracy: 0.9985 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 1863.1432 - regularization_loss: 0.0000e+00 - total_loss: 1863.1432\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2421 - factorized_top_k/top_5_categorical_accuracy: 0.8626 - factorized_top_k/top_10_categorical_accuracy: 0.9704 - factorized_top_k/top_50_categorical_accuracy: 0.9986 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 1850.1090 - regularization_loss: 0.0000e+00 - total_loss: 1850.1090\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2440 - factorized_top_k/top_5_categorical_accuracy: 0.8625 - factorized_top_k/top_10_categorical_accuracy: 0.9707 - factorized_top_k/top_50_categorical_accuracy: 0.9986 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 1861.6643 - regularization_loss: 0.0000e+00 - total_loss: 1861.6643 - val_factorized_top_k/top_1_categorical_accuracy: 0.0230 - val_factorized_top_k/top_5_categorical_accuracy: 0.0772 - val_factorized_top_k/top_10_categorical_accuracy: 0.0898 - val_factorized_top_k/top_50_categorical_accuracy: 0.1164 - val_factorized_top_k/top_100_categorical_accuracy: 0.1338 - val_loss: 57222.3047 - val_regularization_loss: 0.0000e+00 - val_total_loss: 57222.3047\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2435 - factorized_top_k/top_5_categorical_accuracy: 0.8648 - factorized_top_k/top_10_categorical_accuracy: 0.9707 - factorized_top_k/top_50_categorical_accuracy: 0.9987 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 1846.2528 - regularization_loss: 0.0000e+00 - total_loss: 1846.2528\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2415 - factorized_top_k/top_5_categorical_accuracy: 0.8637 - factorized_top_k/top_10_categorical_accuracy: 0.9709 - factorized_top_k/top_50_categorical_accuracy: 0.9987 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 1847.0629 - regularization_loss: 0.0000e+00 - total_loss: 1847.0629\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2423 - factorized_top_k/top_5_categorical_accuracy: 0.8635 - factorized_top_k/top_10_categorical_accuracy: 0.9712 - factorized_top_k/top_50_categorical_accuracy: 0.9987 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 1845.7327 - regularization_loss: 0.0000e+00 - total_loss: 1845.7327\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2406 - factorized_top_k/top_5_categorical_accuracy: 0.8655 - factorized_top_k/top_10_categorical_accuracy: 0.9714 - factorized_top_k/top_50_categorical_accuracy: 0.9988 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 1841.3425 - regularization_loss: 0.0000e+00 - total_loss: 1841.3425\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 143s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2425 - factorized_top_k/top_5_categorical_accuracy: 0.8654 - factorized_top_k/top_10_categorical_accuracy: 0.9717 - factorized_top_k/top_50_categorical_accuracy: 0.9987 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 1839.1530 - regularization_loss: 0.0000e+00 - total_loss: 1839.1530 - val_factorized_top_k/top_1_categorical_accuracy: 0.0214 - val_factorized_top_k/top_5_categorical_accuracy: 0.0773 - val_factorized_top_k/top_10_categorical_accuracy: 0.0901 - val_factorized_top_k/top_50_categorical_accuracy: 0.1169 - val_factorized_top_k/top_100_categorical_accuracy: 0.1337 - val_loss: 57252.6328 - val_regularization_loss: 0.0000e+00 - val_total_loss: 57252.6328\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2442 - factorized_top_k/top_5_categorical_accuracy: 0.8653 - factorized_top_k/top_10_categorical_accuracy: 0.9718 - factorized_top_k/top_50_categorical_accuracy: 0.9988 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 1841.0287 - regularization_loss: 0.0000e+00 - total_loss: 1841.0287\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2416 - factorized_top_k/top_5_categorical_accuracy: 0.8655 - factorized_top_k/top_10_categorical_accuracy: 0.9714 - factorized_top_k/top_50_categorical_accuracy: 0.9988 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 1843.1901 - regularization_loss: 0.0000e+00 - total_loss: 1843.1901\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2407 - factorized_top_k/top_5_categorical_accuracy: 0.8661 - factorized_top_k/top_10_categorical_accuracy: 0.9718 - factorized_top_k/top_50_categorical_accuracy: 0.9988 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 1830.0881 - regularization_loss: 0.0000e+00 - total_loss: 1830.0881\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2421 - factorized_top_k/top_5_categorical_accuracy: 0.8650 - factorized_top_k/top_10_categorical_accuracy: 0.9720 - factorized_top_k/top_50_categorical_accuracy: 0.9988 - factorized_top_k/top_100_categorical_accuracy: 0.9995 - loss: 1829.5221 - regularization_loss: 0.0000e+00 - total_loss: 1829.5221\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2424 - factorized_top_k/top_5_categorical_accuracy: 0.8646 - factorized_top_k/top_10_categorical_accuracy: 0.9722 - factorized_top_k/top_50_categorical_accuracy: 0.9989 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 1827.6618 - regularization_loss: 0.0000e+00 - total_loss: 1827.6618 - val_factorized_top_k/top_1_categorical_accuracy: 0.0243 - val_factorized_top_k/top_5_categorical_accuracy: 0.0772 - val_factorized_top_k/top_10_categorical_accuracy: 0.0892 - val_factorized_top_k/top_50_categorical_accuracy: 0.1163 - val_factorized_top_k/top_100_categorical_accuracy: 0.1344 - val_loss: 57435.1680 - val_regularization_loss: 0.0000e+00 - val_total_loss: 57435.1680\n"
     ]
    }
   ],
   "source": [
    "model = HNMModel(use_timestamps=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model_def = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=100)\n",
    "\n",
    "# train_accuracy = model.evaluate(\n",
    "#     cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "# test_accuracy = model.evaluate(\n",
    "#     cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "# print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "# print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f9af04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7fac9c42dac0>>\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7fac9c42dac0>>\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0044 - factorized_top_k/top_5_categorical_accuracy: 0.0104 - factorized_top_k/top_10_categorical_accuracy: 0.0148 - factorized_top_k/top_50_categorical_accuracy: 0.0355 - factorized_top_k/top_100_categorical_accuracy: 0.0517 - loss: 14850.3757 - regularization_loss: 0.0000e+00 - total_loss: 14850.3757\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0055 - factorized_top_k/top_5_categorical_accuracy: 0.0298 - factorized_top_k/top_10_categorical_accuracy: 0.0450 - factorized_top_k/top_50_categorical_accuracy: 0.1042 - factorized_top_k/top_100_categorical_accuracy: 0.1486 - loss: 13870.0581 - regularization_loss: 0.0000e+00 - total_loss: 13870.0581\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0368 - factorized_top_k/top_5_categorical_accuracy: 0.1391 - factorized_top_k/top_10_categorical_accuracy: 0.1855 - factorized_top_k/top_50_categorical_accuracy: 0.3192 - factorized_top_k/top_100_categorical_accuracy: 0.3918 - loss: 10912.7047 - regularization_loss: 0.0000e+00 - total_loss: 10912.7047\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0954 - factorized_top_k/top_5_categorical_accuracy: 0.2842 - factorized_top_k/top_10_categorical_accuracy: 0.3478 - factorized_top_k/top_50_categorical_accuracy: 0.5185 - factorized_top_k/top_100_categorical_accuracy: 0.6027 - loss: 7851.8604 - regularization_loss: 0.0000e+00 - total_loss: 7851.8604\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - factorized_top_k/top_1_categorical_accuracy: 0.1654 - factorized_top_k/top_5_categorical_accuracy: 0.4235 - factorized_top_k/top_10_categorical_accuracy: 0.5018 - factorized_top_k/top_50_categorical_accuracy: 0.6722 - factorized_top_k/top_100_categorical_accuracy: 0.7445 - loss: 6174.6176 - regularization_loss: 0.0000e+00 - total_loss: 6174.6176WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'customer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7fac9c42dac0>>\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'article_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 139s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.1654 - factorized_top_k/top_5_categorical_accuracy: 0.4235 - factorized_top_k/top_10_categorical_accuracy: 0.5018 - factorized_top_k/top_50_categorical_accuracy: 0.6722 - factorized_top_k/top_100_categorical_accuracy: 0.7445 - loss: 6028.6106 - regularization_loss: 0.0000e+00 - total_loss: 6028.6106 - val_factorized_top_k/top_1_categorical_accuracy: 0.0179 - val_factorized_top_k/top_5_categorical_accuracy: 0.0459 - val_factorized_top_k/top_10_categorical_accuracy: 0.0539 - val_factorized_top_k/top_50_categorical_accuracy: 0.0750 - val_factorized_top_k/top_100_categorical_accuracy: 0.0884 - val_loss: 39880.7812 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39880.7812\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2002 - factorized_top_k/top_5_categorical_accuracy: 0.4897 - factorized_top_k/top_10_categorical_accuracy: 0.5788 - factorized_top_k/top_50_categorical_accuracy: 0.7544 - factorized_top_k/top_100_categorical_accuracy: 0.8185 - loss: 5129.1173 - regularization_loss: 0.0000e+00 - total_loss: 5129.1173\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2174 - factorized_top_k/top_5_categorical_accuracy: 0.5456 - factorized_top_k/top_10_categorical_accuracy: 0.6426 - factorized_top_k/top_50_categorical_accuracy: 0.8102 - factorized_top_k/top_100_categorical_accuracy: 0.8642 - loss: 4539.6036 - regularization_loss: 0.0000e+00 - total_loss: 4539.6036\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2291 - factorized_top_k/top_5_categorical_accuracy: 0.5896 - factorized_top_k/top_10_categorical_accuracy: 0.6892 - factorized_top_k/top_50_categorical_accuracy: 0.8465 - factorized_top_k/top_100_categorical_accuracy: 0.8920 - loss: 4146.8497 - regularization_loss: 0.0000e+00 - total_loss: 4146.8497\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2367 - factorized_top_k/top_5_categorical_accuracy: 0.6205 - factorized_top_k/top_10_categorical_accuracy: 0.7218 - factorized_top_k/top_50_categorical_accuracy: 0.8723 - factorized_top_k/top_100_categorical_accuracy: 0.9113 - loss: 3875.2138 - regularization_loss: 0.0000e+00 - total_loss: 3875.2138\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2384 - factorized_top_k/top_5_categorical_accuracy: 0.6485 - factorized_top_k/top_10_categorical_accuracy: 0.7505 - factorized_top_k/top_50_categorical_accuracy: 0.8913 - factorized_top_k/top_100_categorical_accuracy: 0.9261 - loss: 3637.6352 - regularization_loss: 0.0000e+00 - total_loss: 3637.6352 - val_factorized_top_k/top_1_categorical_accuracy: 0.0215 - val_factorized_top_k/top_5_categorical_accuracy: 0.0593 - val_factorized_top_k/top_10_categorical_accuracy: 0.0691 - val_factorized_top_k/top_50_categorical_accuracy: 0.0909 - val_factorized_top_k/top_100_categorical_accuracy: 0.1055 - val_loss: 46981.3203 - val_regularization_loss: 0.0000e+00 - val_total_loss: 46981.3203\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2466 - factorized_top_k/top_5_categorical_accuracy: 0.6660 - factorized_top_k/top_10_categorical_accuracy: 0.7708 - factorized_top_k/top_50_categorical_accuracy: 0.9057 - factorized_top_k/top_100_categorical_accuracy: 0.9384 - loss: 3474.4662 - regularization_loss: 0.0000e+00 - total_loss: 3474.4662\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2466 - factorized_top_k/top_5_categorical_accuracy: 0.6820 - factorized_top_k/top_10_categorical_accuracy: 0.7886 - factorized_top_k/top_50_categorical_accuracy: 0.9177 - factorized_top_k/top_100_categorical_accuracy: 0.9462 - loss: 3323.3544 - regularization_loss: 0.0000e+00 - total_loss: 3323.3544\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2496 - factorized_top_k/top_5_categorical_accuracy: 0.6953 - factorized_top_k/top_10_categorical_accuracy: 0.8054 - factorized_top_k/top_50_categorical_accuracy: 0.9273 - factorized_top_k/top_100_categorical_accuracy: 0.9528 - loss: 3211.0440 - regularization_loss: 0.0000e+00 - total_loss: 3211.0440\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2501 - factorized_top_k/top_5_categorical_accuracy: 0.7074 - factorized_top_k/top_10_categorical_accuracy: 0.8158 - factorized_top_k/top_50_categorical_accuracy: 0.9352 - factorized_top_k/top_100_categorical_accuracy: 0.9576 - loss: 3105.5832 - regularization_loss: 0.0000e+00 - total_loss: 3105.5832\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2527 - factorized_top_k/top_5_categorical_accuracy: 0.7193 - factorized_top_k/top_10_categorical_accuracy: 0.8295 - factorized_top_k/top_50_categorical_accuracy: 0.9409 - factorized_top_k/top_100_categorical_accuracy: 0.9622 - loss: 3023.0158 - regularization_loss: 0.0000e+00 - total_loss: 3023.0158 - val_factorized_top_k/top_1_categorical_accuracy: 0.0227 - val_factorized_top_k/top_5_categorical_accuracy: 0.0630 - val_factorized_top_k/top_10_categorical_accuracy: 0.0733 - val_factorized_top_k/top_50_categorical_accuracy: 0.0974 - val_factorized_top_k/top_100_categorical_accuracy: 0.1113 - val_loss: 51403.2969 - val_regularization_loss: 0.0000e+00 - val_total_loss: 51403.2969\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2558 - factorized_top_k/top_5_categorical_accuracy: 0.7291 - factorized_top_k/top_10_categorical_accuracy: 0.8390 - factorized_top_k/top_50_categorical_accuracy: 0.9467 - factorized_top_k/top_100_categorical_accuracy: 0.9659 - loss: 2945.4108 - regularization_loss: 0.0000e+00 - total_loss: 2945.4108\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2537 - factorized_top_k/top_5_categorical_accuracy: 0.7377 - factorized_top_k/top_10_categorical_accuracy: 0.8467 - factorized_top_k/top_50_categorical_accuracy: 0.9513 - factorized_top_k/top_100_categorical_accuracy: 0.9686 - loss: 2876.6607 - regularization_loss: 0.0000e+00 - total_loss: 2876.6607\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2540 - factorized_top_k/top_5_categorical_accuracy: 0.7459 - factorized_top_k/top_10_categorical_accuracy: 0.8567 - factorized_top_k/top_50_categorical_accuracy: 0.9552 - factorized_top_k/top_100_categorical_accuracy: 0.9716 - loss: 2810.0343 - regularization_loss: 0.0000e+00 - total_loss: 2810.0343\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2569 - factorized_top_k/top_5_categorical_accuracy: 0.7546 - factorized_top_k/top_10_categorical_accuracy: 0.8640 - factorized_top_k/top_50_categorical_accuracy: 0.9591 - factorized_top_k/top_100_categorical_accuracy: 0.9739 - loss: 2750.8099 - regularization_loss: 0.0000e+00 - total_loss: 2750.8099\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2577 - factorized_top_k/top_5_categorical_accuracy: 0.7614 - factorized_top_k/top_10_categorical_accuracy: 0.8721 - factorized_top_k/top_50_categorical_accuracy: 0.9618 - factorized_top_k/top_100_categorical_accuracy: 0.9759 - loss: 2707.4398 - regularization_loss: 0.0000e+00 - total_loss: 2707.4398 - val_factorized_top_k/top_1_categorical_accuracy: 0.0216 - val_factorized_top_k/top_5_categorical_accuracy: 0.0662 - val_factorized_top_k/top_10_categorical_accuracy: 0.0765 - val_factorized_top_k/top_50_categorical_accuracy: 0.0999 - val_factorized_top_k/top_100_categorical_accuracy: 0.1157 - val_loss: 54152.6797 - val_regularization_loss: 0.0000e+00 - val_total_loss: 54152.6797\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2601 - factorized_top_k/top_5_categorical_accuracy: 0.7689 - factorized_top_k/top_10_categorical_accuracy: 0.8771 - factorized_top_k/top_50_categorical_accuracy: 0.9650 - factorized_top_k/top_100_categorical_accuracy: 0.9779 - loss: 2662.3734 - regularization_loss: 0.0000e+00 - total_loss: 2662.3734\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2597 - factorized_top_k/top_5_categorical_accuracy: 0.7746 - factorized_top_k/top_10_categorical_accuracy: 0.8830 - factorized_top_k/top_50_categorical_accuracy: 0.9670 - factorized_top_k/top_100_categorical_accuracy: 0.9795 - loss: 2625.7732 - regularization_loss: 0.0000e+00 - total_loss: 2625.7732\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2568 - factorized_top_k/top_5_categorical_accuracy: 0.7779 - factorized_top_k/top_10_categorical_accuracy: 0.8880 - factorized_top_k/top_50_categorical_accuracy: 0.9689 - factorized_top_k/top_100_categorical_accuracy: 0.9804 - loss: 2584.4837 - regularization_loss: 0.0000e+00 - total_loss: 2584.4837\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2572 - factorized_top_k/top_5_categorical_accuracy: 0.7840 - factorized_top_k/top_10_categorical_accuracy: 0.8934 - factorized_top_k/top_50_categorical_accuracy: 0.9713 - factorized_top_k/top_100_categorical_accuracy: 0.9819 - loss: 2533.1825 - regularization_loss: 0.0000e+00 - total_loss: 2533.1825\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2567 - factorized_top_k/top_5_categorical_accuracy: 0.7888 - factorized_top_k/top_10_categorical_accuracy: 0.8973 - factorized_top_k/top_50_categorical_accuracy: 0.9730 - factorized_top_k/top_100_categorical_accuracy: 0.9827 - loss: 2506.6199 - regularization_loss: 0.0000e+00 - total_loss: 2506.6199 - val_factorized_top_k/top_1_categorical_accuracy: 0.0224 - val_factorized_top_k/top_5_categorical_accuracy: 0.0684 - val_factorized_top_k/top_10_categorical_accuracy: 0.0795 - val_factorized_top_k/top_50_categorical_accuracy: 0.1019 - val_factorized_top_k/top_100_categorical_accuracy: 0.1169 - val_loss: 56808.5938 - val_regularization_loss: 0.0000e+00 - val_total_loss: 56808.5938\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2587 - factorized_top_k/top_5_categorical_accuracy: 0.7929 - factorized_top_k/top_10_categorical_accuracy: 0.9016 - factorized_top_k/top_50_categorical_accuracy: 0.9747 - factorized_top_k/top_100_categorical_accuracy: 0.9844 - loss: 2467.2399 - regularization_loss: 0.0000e+00 - total_loss: 2467.2399\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2581 - factorized_top_k/top_5_categorical_accuracy: 0.7974 - factorized_top_k/top_10_categorical_accuracy: 0.9054 - factorized_top_k/top_50_categorical_accuracy: 0.9759 - factorized_top_k/top_100_categorical_accuracy: 0.9851 - loss: 2436.9822 - regularization_loss: 0.0000e+00 - total_loss: 2436.9822\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 116s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2586 - factorized_top_k/top_5_categorical_accuracy: 0.8017 - factorized_top_k/top_10_categorical_accuracy: 0.9097 - factorized_top_k/top_50_categorical_accuracy: 0.9773 - factorized_top_k/top_100_categorical_accuracy: 0.9862 - loss: 2413.7881 - regularization_loss: 0.0000e+00 - total_loss: 2413.7881\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2588 - factorized_top_k/top_5_categorical_accuracy: 0.8062 - factorized_top_k/top_10_categorical_accuracy: 0.9132 - factorized_top_k/top_50_categorical_accuracy: 0.9789 - factorized_top_k/top_100_categorical_accuracy: 0.9872 - loss: 2403.4073 - regularization_loss: 0.0000e+00 - total_loss: 2403.4073\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 143s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2572 - factorized_top_k/top_5_categorical_accuracy: 0.8077 - factorized_top_k/top_10_categorical_accuracy: 0.9157 - factorized_top_k/top_50_categorical_accuracy: 0.9799 - factorized_top_k/top_100_categorical_accuracy: 0.9879 - loss: 2367.7158 - regularization_loss: 0.0000e+00 - total_loss: 2367.7158 - val_factorized_top_k/top_1_categorical_accuracy: 0.0229 - val_factorized_top_k/top_5_categorical_accuracy: 0.0691 - val_factorized_top_k/top_10_categorical_accuracy: 0.0811 - val_factorized_top_k/top_50_categorical_accuracy: 0.1036 - val_factorized_top_k/top_100_categorical_accuracy: 0.1205 - val_loss: 57092.1836 - val_regularization_loss: 0.0000e+00 - val_total_loss: 57092.1836\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2580 - factorized_top_k/top_5_categorical_accuracy: 0.8112 - factorized_top_k/top_10_categorical_accuracy: 0.9186 - factorized_top_k/top_50_categorical_accuracy: 0.9814 - factorized_top_k/top_100_categorical_accuracy: 0.9888 - loss: 2346.4254 - regularization_loss: 0.0000e+00 - total_loss: 2346.4254\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2571 - factorized_top_k/top_5_categorical_accuracy: 0.8153 - factorized_top_k/top_10_categorical_accuracy: 0.9220 - factorized_top_k/top_50_categorical_accuracy: 0.9821 - factorized_top_k/top_100_categorical_accuracy: 0.9894 - loss: 2336.1860 - regularization_loss: 0.0000e+00 - total_loss: 2336.1860\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2572 - factorized_top_k/top_5_categorical_accuracy: 0.8168 - factorized_top_k/top_10_categorical_accuracy: 0.9243 - factorized_top_k/top_50_categorical_accuracy: 0.9833 - factorized_top_k/top_100_categorical_accuracy: 0.9900 - loss: 2299.5532 - regularization_loss: 0.0000e+00 - total_loss: 2299.5532\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2578 - factorized_top_k/top_5_categorical_accuracy: 0.8200 - factorized_top_k/top_10_categorical_accuracy: 0.9269 - factorized_top_k/top_50_categorical_accuracy: 0.9839 - factorized_top_k/top_100_categorical_accuracy: 0.9904 - loss: 2276.0312 - regularization_loss: 0.0000e+00 - total_loss: 2276.0312\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 139s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2544 - factorized_top_k/top_5_categorical_accuracy: 0.8232 - factorized_top_k/top_10_categorical_accuracy: 0.9283 - factorized_top_k/top_50_categorical_accuracy: 0.9847 - factorized_top_k/top_100_categorical_accuracy: 0.9909 - loss: 2264.4803 - regularization_loss: 0.0000e+00 - total_loss: 2264.4803 - val_factorized_top_k/top_1_categorical_accuracy: 0.0229 - val_factorized_top_k/top_5_categorical_accuracy: 0.0697 - val_factorized_top_k/top_10_categorical_accuracy: 0.0819 - val_factorized_top_k/top_50_categorical_accuracy: 0.1046 - val_factorized_top_k/top_100_categorical_accuracy: 0.1209 - val_loss: 57982.7383 - val_regularization_loss: 0.0000e+00 - val_total_loss: 57982.7383\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2592 - factorized_top_k/top_5_categorical_accuracy: 0.8243 - factorized_top_k/top_10_categorical_accuracy: 0.9300 - factorized_top_k/top_50_categorical_accuracy: 0.9857 - factorized_top_k/top_100_categorical_accuracy: 0.9915 - loss: 2233.4806 - regularization_loss: 0.0000e+00 - total_loss: 2233.4806\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2569 - factorized_top_k/top_5_categorical_accuracy: 0.8261 - factorized_top_k/top_10_categorical_accuracy: 0.9332 - factorized_top_k/top_50_categorical_accuracy: 0.9861 - factorized_top_k/top_100_categorical_accuracy: 0.9916 - loss: 2229.7414 - regularization_loss: 0.0000e+00 - total_loss: 2229.7414\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2548 - factorized_top_k/top_5_categorical_accuracy: 0.8294 - factorized_top_k/top_10_categorical_accuracy: 0.9355 - factorized_top_k/top_50_categorical_accuracy: 0.9870 - factorized_top_k/top_100_categorical_accuracy: 0.9921 - loss: 2203.3037 - regularization_loss: 0.0000e+00 - total_loss: 2203.3037\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2569 - factorized_top_k/top_5_categorical_accuracy: 0.8307 - factorized_top_k/top_10_categorical_accuracy: 0.9367 - factorized_top_k/top_50_categorical_accuracy: 0.9876 - factorized_top_k/top_100_categorical_accuracy: 0.9923 - loss: 2206.4844 - regularization_loss: 0.0000e+00 - total_loss: 2206.4844\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2576 - factorized_top_k/top_5_categorical_accuracy: 0.8328 - factorized_top_k/top_10_categorical_accuracy: 0.9393 - factorized_top_k/top_50_categorical_accuracy: 0.9882 - factorized_top_k/top_100_categorical_accuracy: 0.9926 - loss: 2189.3258 - regularization_loss: 0.0000e+00 - total_loss: 2189.3258 - val_factorized_top_k/top_1_categorical_accuracy: 0.0235 - val_factorized_top_k/top_5_categorical_accuracy: 0.0715 - val_factorized_top_k/top_10_categorical_accuracy: 0.0829 - val_factorized_top_k/top_50_categorical_accuracy: 0.1052 - val_factorized_top_k/top_100_categorical_accuracy: 0.1209 - val_loss: 58801.4336 - val_regularization_loss: 0.0000e+00 - val_total_loss: 58801.4336\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2554 - factorized_top_k/top_5_categorical_accuracy: 0.8350 - factorized_top_k/top_10_categorical_accuracy: 0.9398 - factorized_top_k/top_50_categorical_accuracy: 0.9888 - factorized_top_k/top_100_categorical_accuracy: 0.9933 - loss: 2173.6495 - regularization_loss: 0.0000e+00 - total_loss: 2173.6495\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2555 - factorized_top_k/top_5_categorical_accuracy: 0.8356 - factorized_top_k/top_10_categorical_accuracy: 0.9409 - factorized_top_k/top_50_categorical_accuracy: 0.9890 - factorized_top_k/top_100_categorical_accuracy: 0.9937 - loss: 2155.9164 - regularization_loss: 0.0000e+00 - total_loss: 2155.9164\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2553 - factorized_top_k/top_5_categorical_accuracy: 0.8382 - factorized_top_k/top_10_categorical_accuracy: 0.9427 - factorized_top_k/top_50_categorical_accuracy: 0.9895 - factorized_top_k/top_100_categorical_accuracy: 0.9939 - loss: 2145.0004 - regularization_loss: 0.0000e+00 - total_loss: 2145.0004\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2540 - factorized_top_k/top_5_categorical_accuracy: 0.8405 - factorized_top_k/top_10_categorical_accuracy: 0.9447 - factorized_top_k/top_50_categorical_accuracy: 0.9898 - factorized_top_k/top_100_categorical_accuracy: 0.9940 - loss: 2136.6437 - regularization_loss: 0.0000e+00 - total_loss: 2136.6437\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 139s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2528 - factorized_top_k/top_5_categorical_accuracy: 0.8406 - factorized_top_k/top_10_categorical_accuracy: 0.9452 - factorized_top_k/top_50_categorical_accuracy: 0.9902 - factorized_top_k/top_100_categorical_accuracy: 0.9943 - loss: 2120.3709 - regularization_loss: 0.0000e+00 - total_loss: 2120.3709 - val_factorized_top_k/top_1_categorical_accuracy: 0.0210 - val_factorized_top_k/top_5_categorical_accuracy: 0.0708 - val_factorized_top_k/top_10_categorical_accuracy: 0.0838 - val_factorized_top_k/top_50_categorical_accuracy: 0.1067 - val_factorized_top_k/top_100_categorical_accuracy: 0.1232 - val_loss: 59708.9297 - val_regularization_loss: 0.0000e+00 - val_total_loss: 59708.9297\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2529 - factorized_top_k/top_5_categorical_accuracy: 0.8420 - factorized_top_k/top_10_categorical_accuracy: 0.9467 - factorized_top_k/top_50_categorical_accuracy: 0.9908 - factorized_top_k/top_100_categorical_accuracy: 0.9946 - loss: 2105.6102 - regularization_loss: 0.0000e+00 - total_loss: 2105.6102\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2544 - factorized_top_k/top_5_categorical_accuracy: 0.8431 - factorized_top_k/top_10_categorical_accuracy: 0.9477 - factorized_top_k/top_50_categorical_accuracy: 0.9909 - factorized_top_k/top_100_categorical_accuracy: 0.9947 - loss: 2108.5243 - regularization_loss: 0.0000e+00 - total_loss: 2108.5243\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2534 - factorized_top_k/top_5_categorical_accuracy: 0.8444 - factorized_top_k/top_10_categorical_accuracy: 0.9492 - factorized_top_k/top_50_categorical_accuracy: 0.9912 - factorized_top_k/top_100_categorical_accuracy: 0.9949 - loss: 2093.5657 - regularization_loss: 0.0000e+00 - total_loss: 2093.5657\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2524 - factorized_top_k/top_5_categorical_accuracy: 0.8456 - factorized_top_k/top_10_categorical_accuracy: 0.9495 - factorized_top_k/top_50_categorical_accuracy: 0.9915 - factorized_top_k/top_100_categorical_accuracy: 0.9950 - loss: 2079.0529 - regularization_loss: 0.0000e+00 - total_loss: 2079.0529\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2533 - factorized_top_k/top_5_categorical_accuracy: 0.8468 - factorized_top_k/top_10_categorical_accuracy: 0.9512 - factorized_top_k/top_50_categorical_accuracy: 0.9920 - factorized_top_k/top_100_categorical_accuracy: 0.9955 - loss: 2079.2177 - regularization_loss: 0.0000e+00 - total_loss: 2079.2177 - val_factorized_top_k/top_1_categorical_accuracy: 0.0246 - val_factorized_top_k/top_5_categorical_accuracy: 0.0715 - val_factorized_top_k/top_10_categorical_accuracy: 0.0835 - val_factorized_top_k/top_50_categorical_accuracy: 0.1059 - val_factorized_top_k/top_100_categorical_accuracy: 0.1227 - val_loss: 60253.2188 - val_regularization_loss: 0.0000e+00 - val_total_loss: 60253.2188\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2519 - factorized_top_k/top_5_categorical_accuracy: 0.8486 - factorized_top_k/top_10_categorical_accuracy: 0.9517 - factorized_top_k/top_50_categorical_accuracy: 0.9924 - factorized_top_k/top_100_categorical_accuracy: 0.9955 - loss: 2067.6469 - regularization_loss: 0.0000e+00 - total_loss: 2067.6469\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2525 - factorized_top_k/top_5_categorical_accuracy: 0.8487 - factorized_top_k/top_10_categorical_accuracy: 0.9528 - factorized_top_k/top_50_categorical_accuracy: 0.9925 - factorized_top_k/top_100_categorical_accuracy: 0.9957 - loss: 2057.9572 - regularization_loss: 0.0000e+00 - total_loss: 2057.9572\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2540 - factorized_top_k/top_5_categorical_accuracy: 0.8492 - factorized_top_k/top_10_categorical_accuracy: 0.9542 - factorized_top_k/top_50_categorical_accuracy: 0.9928 - factorized_top_k/top_100_categorical_accuracy: 0.9959 - loss: 2054.9237 - regularization_loss: 0.0000e+00 - total_loss: 2054.9237\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2534 - factorized_top_k/top_5_categorical_accuracy: 0.8502 - factorized_top_k/top_10_categorical_accuracy: 0.9537 - factorized_top_k/top_50_categorical_accuracy: 0.9929 - factorized_top_k/top_100_categorical_accuracy: 0.9960 - loss: 2048.1166 - regularization_loss: 0.0000e+00 - total_loss: 2048.1166\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2518 - factorized_top_k/top_5_categorical_accuracy: 0.8519 - factorized_top_k/top_10_categorical_accuracy: 0.9544 - factorized_top_k/top_50_categorical_accuracy: 0.9931 - factorized_top_k/top_100_categorical_accuracy: 0.9961 - loss: 2031.3385 - regularization_loss: 0.0000e+00 - total_loss: 2031.3385 - val_factorized_top_k/top_1_categorical_accuracy: 0.0205 - val_factorized_top_k/top_5_categorical_accuracy: 0.0724 - val_factorized_top_k/top_10_categorical_accuracy: 0.0846 - val_factorized_top_k/top_50_categorical_accuracy: 0.1068 - val_factorized_top_k/top_100_categorical_accuracy: 0.1230 - val_loss: 60509.9141 - val_regularization_loss: 0.0000e+00 - val_total_loss: 60509.9141\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2534 - factorized_top_k/top_5_categorical_accuracy: 0.8515 - factorized_top_k/top_10_categorical_accuracy: 0.9552 - factorized_top_k/top_50_categorical_accuracy: 0.9936 - factorized_top_k/top_100_categorical_accuracy: 0.9963 - loss: 2018.0205 - regularization_loss: 0.0000e+00 - total_loss: 2018.0205\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2518 - factorized_top_k/top_5_categorical_accuracy: 0.8533 - factorized_top_k/top_10_categorical_accuracy: 0.9566 - factorized_top_k/top_50_categorical_accuracy: 0.9937 - factorized_top_k/top_100_categorical_accuracy: 0.9964 - loss: 2006.9141 - regularization_loss: 0.0000e+00 - total_loss: 2006.9141\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2515 - factorized_top_k/top_5_categorical_accuracy: 0.8537 - factorized_top_k/top_10_categorical_accuracy: 0.9571 - factorized_top_k/top_50_categorical_accuracy: 0.9940 - factorized_top_k/top_100_categorical_accuracy: 0.9966 - loss: 2008.0165 - regularization_loss: 0.0000e+00 - total_loss: 2008.0165\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2505 - factorized_top_k/top_5_categorical_accuracy: 0.8540 - factorized_top_k/top_10_categorical_accuracy: 0.9577 - factorized_top_k/top_50_categorical_accuracy: 0.9942 - factorized_top_k/top_100_categorical_accuracy: 0.9967 - loss: 2003.4396 - regularization_loss: 0.0000e+00 - total_loss: 2003.4396\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 139s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2514 - factorized_top_k/top_5_categorical_accuracy: 0.8553 - factorized_top_k/top_10_categorical_accuracy: 0.9577 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9968 - loss: 2000.0224 - regularization_loss: 0.0000e+00 - total_loss: 2000.0224 - val_factorized_top_k/top_1_categorical_accuracy: 0.0231 - val_factorized_top_k/top_5_categorical_accuracy: 0.0732 - val_factorized_top_k/top_10_categorical_accuracy: 0.0842 - val_factorized_top_k/top_50_categorical_accuracy: 0.1073 - val_factorized_top_k/top_100_categorical_accuracy: 0.1240 - val_loss: 61015.6172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 61015.6172\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2512 - factorized_top_k/top_5_categorical_accuracy: 0.8559 - factorized_top_k/top_10_categorical_accuracy: 0.9590 - factorized_top_k/top_50_categorical_accuracy: 0.9945 - factorized_top_k/top_100_categorical_accuracy: 0.9968 - loss: 1991.7917 - regularization_loss: 0.0000e+00 - total_loss: 1991.7917\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2521 - factorized_top_k/top_5_categorical_accuracy: 0.8569 - factorized_top_k/top_10_categorical_accuracy: 0.9593 - factorized_top_k/top_50_categorical_accuracy: 0.9946 - factorized_top_k/top_100_categorical_accuracy: 0.9969 - loss: 1983.4076 - regularization_loss: 0.0000e+00 - total_loss: 1983.4076\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2478 - factorized_top_k/top_5_categorical_accuracy: 0.8570 - factorized_top_k/top_10_categorical_accuracy: 0.9594 - factorized_top_k/top_50_categorical_accuracy: 0.9948 - factorized_top_k/top_100_categorical_accuracy: 0.9972 - loss: 1980.9328 - regularization_loss: 0.0000e+00 - total_loss: 1980.9328\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2500 - factorized_top_k/top_5_categorical_accuracy: 0.8573 - factorized_top_k/top_10_categorical_accuracy: 0.9598 - factorized_top_k/top_50_categorical_accuracy: 0.9950 - factorized_top_k/top_100_categorical_accuracy: 0.9972 - loss: 1976.3531 - regularization_loss: 0.0000e+00 - total_loss: 1976.3531\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2486 - factorized_top_k/top_5_categorical_accuracy: 0.8585 - factorized_top_k/top_10_categorical_accuracy: 0.9614 - factorized_top_k/top_50_categorical_accuracy: 0.9952 - factorized_top_k/top_100_categorical_accuracy: 0.9974 - loss: 1969.8311 - regularization_loss: 0.0000e+00 - total_loss: 1969.8311 - val_factorized_top_k/top_1_categorical_accuracy: 0.0225 - val_factorized_top_k/top_5_categorical_accuracy: 0.0724 - val_factorized_top_k/top_10_categorical_accuracy: 0.0845 - val_factorized_top_k/top_50_categorical_accuracy: 0.1077 - val_factorized_top_k/top_100_categorical_accuracy: 0.1249 - val_loss: 61704.2578 - val_regularization_loss: 0.0000e+00 - val_total_loss: 61704.2578\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2480 - factorized_top_k/top_5_categorical_accuracy: 0.8582 - factorized_top_k/top_10_categorical_accuracy: 0.9612 - factorized_top_k/top_50_categorical_accuracy: 0.9952 - factorized_top_k/top_100_categorical_accuracy: 0.9973 - loss: 1952.8821 - regularization_loss: 0.0000e+00 - total_loss: 1952.8821\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2503 - factorized_top_k/top_5_categorical_accuracy: 0.8592 - factorized_top_k/top_10_categorical_accuracy: 0.9621 - factorized_top_k/top_50_categorical_accuracy: 0.9954 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 1947.5901 - regularization_loss: 0.0000e+00 - total_loss: 1947.5901\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2490 - factorized_top_k/top_5_categorical_accuracy: 0.8605 - factorized_top_k/top_10_categorical_accuracy: 0.9622 - factorized_top_k/top_50_categorical_accuracy: 0.9955 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 1951.3944 - regularization_loss: 0.0000e+00 - total_loss: 1951.3944\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2481 - factorized_top_k/top_5_categorical_accuracy: 0.8600 - factorized_top_k/top_10_categorical_accuracy: 0.9628 - factorized_top_k/top_50_categorical_accuracy: 0.9956 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 1947.8404 - regularization_loss: 0.0000e+00 - total_loss: 1947.8404\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 140s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2483 - factorized_top_k/top_5_categorical_accuracy: 0.8603 - factorized_top_k/top_10_categorical_accuracy: 0.9633 - factorized_top_k/top_50_categorical_accuracy: 0.9959 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 1934.2964 - regularization_loss: 0.0000e+00 - total_loss: 1934.2964 - val_factorized_top_k/top_1_categorical_accuracy: 0.0225 - val_factorized_top_k/top_5_categorical_accuracy: 0.0733 - val_factorized_top_k/top_10_categorical_accuracy: 0.0856 - val_factorized_top_k/top_50_categorical_accuracy: 0.1081 - val_factorized_top_k/top_100_categorical_accuracy: 0.1244 - val_loss: 61974.4375 - val_regularization_loss: 0.0000e+00 - val_total_loss: 61974.4375\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2484 - factorized_top_k/top_5_categorical_accuracy: 0.8613 - factorized_top_k/top_10_categorical_accuracy: 0.9639 - factorized_top_k/top_50_categorical_accuracy: 0.9959 - factorized_top_k/top_100_categorical_accuracy: 0.9978 - loss: 1937.6929 - regularization_loss: 0.0000e+00 - total_loss: 1937.6929\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2475 - factorized_top_k/top_5_categorical_accuracy: 0.8609 - factorized_top_k/top_10_categorical_accuracy: 0.9641 - factorized_top_k/top_50_categorical_accuracy: 0.9959 - factorized_top_k/top_100_categorical_accuracy: 0.9980 - loss: 1935.9907 - regularization_loss: 0.0000e+00 - total_loss: 1935.9907\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2482 - factorized_top_k/top_5_categorical_accuracy: 0.8628 - factorized_top_k/top_10_categorical_accuracy: 0.9645 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9979 - loss: 1934.5008 - regularization_loss: 0.0000e+00 - total_loss: 1934.5008\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2464 - factorized_top_k/top_5_categorical_accuracy: 0.8622 - factorized_top_k/top_10_categorical_accuracy: 0.9646 - factorized_top_k/top_50_categorical_accuracy: 0.9962 - factorized_top_k/top_100_categorical_accuracy: 0.9980 - loss: 1926.1883 - regularization_loss: 0.0000e+00 - total_loss: 1926.1883\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2503 - factorized_top_k/top_5_categorical_accuracy: 0.8625 - factorized_top_k/top_10_categorical_accuracy: 0.9656 - factorized_top_k/top_50_categorical_accuracy: 0.9962 - factorized_top_k/top_100_categorical_accuracy: 0.9980 - loss: 1925.9313 - regularization_loss: 0.0000e+00 - total_loss: 1925.9313 - val_factorized_top_k/top_1_categorical_accuracy: 0.0219 - val_factorized_top_k/top_5_categorical_accuracy: 0.0741 - val_factorized_top_k/top_10_categorical_accuracy: 0.0858 - val_factorized_top_k/top_50_categorical_accuracy: 0.1079 - val_factorized_top_k/top_100_categorical_accuracy: 0.1251 - val_loss: 62358.2539 - val_regularization_loss: 0.0000e+00 - val_total_loss: 62358.2539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2462 - factorized_top_k/top_5_categorical_accuracy: 0.8637 - factorized_top_k/top_10_categorical_accuracy: 0.9657 - factorized_top_k/top_50_categorical_accuracy: 0.9963 - factorized_top_k/top_100_categorical_accuracy: 0.9980 - loss: 1910.9074 - regularization_loss: 0.0000e+00 - total_loss: 1910.9074\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2462 - factorized_top_k/top_5_categorical_accuracy: 0.8637 - factorized_top_k/top_10_categorical_accuracy: 0.9660 - factorized_top_k/top_50_categorical_accuracy: 0.9966 - factorized_top_k/top_100_categorical_accuracy: 0.9981 - loss: 1899.2411 - regularization_loss: 0.0000e+00 - total_loss: 1899.2411\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2474 - factorized_top_k/top_5_categorical_accuracy: 0.8637 - factorized_top_k/top_10_categorical_accuracy: 0.9663 - factorized_top_k/top_50_categorical_accuracy: 0.9965 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - loss: 1905.8456 - regularization_loss: 0.0000e+00 - total_loss: 1905.8456\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2463 - factorized_top_k/top_5_categorical_accuracy: 0.8641 - factorized_top_k/top_10_categorical_accuracy: 0.9662 - factorized_top_k/top_50_categorical_accuracy: 0.9967 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - loss: 1902.7013 - regularization_loss: 0.0000e+00 - total_loss: 1902.7013\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2454 - factorized_top_k/top_5_categorical_accuracy: 0.8653 - factorized_top_k/top_10_categorical_accuracy: 0.9663 - factorized_top_k/top_50_categorical_accuracy: 0.9967 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - loss: 1901.2055 - regularization_loss: 0.0000e+00 - total_loss: 1901.2055 - val_factorized_top_k/top_1_categorical_accuracy: 0.0236 - val_factorized_top_k/top_5_categorical_accuracy: 0.0733 - val_factorized_top_k/top_10_categorical_accuracy: 0.0856 - val_factorized_top_k/top_50_categorical_accuracy: 0.1084 - val_factorized_top_k/top_100_categorical_accuracy: 0.1251 - val_loss: 62323.3320 - val_regularization_loss: 0.0000e+00 - val_total_loss: 62323.3320\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2484 - factorized_top_k/top_5_categorical_accuracy: 0.8655 - factorized_top_k/top_10_categorical_accuracy: 0.9674 - factorized_top_k/top_50_categorical_accuracy: 0.9968 - factorized_top_k/top_100_categorical_accuracy: 0.9983 - loss: 1897.0131 - regularization_loss: 0.0000e+00 - total_loss: 1897.0131\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2455 - factorized_top_k/top_5_categorical_accuracy: 0.8654 - factorized_top_k/top_10_categorical_accuracy: 0.9679 - factorized_top_k/top_50_categorical_accuracy: 0.9968 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 1883.8970 - regularization_loss: 0.0000e+00 - total_loss: 1883.8970\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2446 - factorized_top_k/top_5_categorical_accuracy: 0.8651 - factorized_top_k/top_10_categorical_accuracy: 0.9676 - factorized_top_k/top_50_categorical_accuracy: 0.9968 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 1877.1319 - regularization_loss: 0.0000e+00 - total_loss: 1877.1319\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2454 - factorized_top_k/top_5_categorical_accuracy: 0.8663 - factorized_top_k/top_10_categorical_accuracy: 0.9682 - factorized_top_k/top_50_categorical_accuracy: 0.9969 - factorized_top_k/top_100_categorical_accuracy: 0.9985 - loss: 1877.5830 - regularization_loss: 0.0000e+00 - total_loss: 1877.5830\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 142s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2449 - factorized_top_k/top_5_categorical_accuracy: 0.8666 - factorized_top_k/top_10_categorical_accuracy: 0.9676 - factorized_top_k/top_50_categorical_accuracy: 0.9971 - factorized_top_k/top_100_categorical_accuracy: 0.9985 - loss: 1875.0328 - regularization_loss: 0.0000e+00 - total_loss: 1875.0328 - val_factorized_top_k/top_1_categorical_accuracy: 0.0224 - val_factorized_top_k/top_5_categorical_accuracy: 0.0736 - val_factorized_top_k/top_10_categorical_accuracy: 0.0856 - val_factorized_top_k/top_50_categorical_accuracy: 0.1086 - val_factorized_top_k/top_100_categorical_accuracy: 0.1257 - val_loss: 62566.7617 - val_regularization_loss: 0.0000e+00 - val_total_loss: 62566.7617\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2460 - factorized_top_k/top_5_categorical_accuracy: 0.8680 - factorized_top_k/top_10_categorical_accuracy: 0.9687 - factorized_top_k/top_50_categorical_accuracy: 0.9973 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 1877.1005 - regularization_loss: 0.0000e+00 - total_loss: 1877.1005\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2452 - factorized_top_k/top_5_categorical_accuracy: 0.8662 - factorized_top_k/top_10_categorical_accuracy: 0.9685 - factorized_top_k/top_50_categorical_accuracy: 0.9972 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 1871.4364 - regularization_loss: 0.0000e+00 - total_loss: 1871.4364\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2433 - factorized_top_k/top_5_categorical_accuracy: 0.8670 - factorized_top_k/top_10_categorical_accuracy: 0.9689 - factorized_top_k/top_50_categorical_accuracy: 0.9973 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 1861.5641 - regularization_loss: 0.0000e+00 - total_loss: 1861.5641\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2460 - factorized_top_k/top_5_categorical_accuracy: 0.8674 - factorized_top_k/top_10_categorical_accuracy: 0.9693 - factorized_top_k/top_50_categorical_accuracy: 0.9974 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 1862.9859 - regularization_loss: 0.0000e+00 - total_loss: 1862.9859\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2435 - factorized_top_k/top_5_categorical_accuracy: 0.8677 - factorized_top_k/top_10_categorical_accuracy: 0.9693 - factorized_top_k/top_50_categorical_accuracy: 0.9974 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 1862.8934 - regularization_loss: 0.0000e+00 - total_loss: 1862.8934 - val_factorized_top_k/top_1_categorical_accuracy: 0.0225 - val_factorized_top_k/top_5_categorical_accuracy: 0.0738 - val_factorized_top_k/top_10_categorical_accuracy: 0.0855 - val_factorized_top_k/top_50_categorical_accuracy: 0.1088 - val_factorized_top_k/top_100_categorical_accuracy: 0.1258 - val_loss: 62580.8750 - val_regularization_loss: 0.0000e+00 - val_total_loss: 62580.8750\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2443 - factorized_top_k/top_5_categorical_accuracy: 0.8676 - factorized_top_k/top_10_categorical_accuracy: 0.9699 - factorized_top_k/top_50_categorical_accuracy: 0.9976 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 1855.7409 - regularization_loss: 0.0000e+00 - total_loss: 1855.7409\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2452 - factorized_top_k/top_5_categorical_accuracy: 0.8690 - factorized_top_k/top_10_categorical_accuracy: 0.9700 - factorized_top_k/top_50_categorical_accuracy: 0.9975 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 1851.4089 - regularization_loss: 0.0000e+00 - total_loss: 1851.4089\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2460 - factorized_top_k/top_5_categorical_accuracy: 0.8692 - factorized_top_k/top_10_categorical_accuracy: 0.9703 - factorized_top_k/top_50_categorical_accuracy: 0.9976 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 1853.3614 - regularization_loss: 0.0000e+00 - total_loss: 1853.3614\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2457 - factorized_top_k/top_5_categorical_accuracy: 0.8684 - factorized_top_k/top_10_categorical_accuracy: 0.9704 - factorized_top_k/top_50_categorical_accuracy: 0.9977 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 1856.4961 - regularization_loss: 0.0000e+00 - total_loss: 1856.4961\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 143s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.2422 - factorized_top_k/top_5_categorical_accuracy: 0.8692 - factorized_top_k/top_10_categorical_accuracy: 0.9704 - factorized_top_k/top_50_categorical_accuracy: 0.9976 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 1842.0861 - regularization_loss: 0.0000e+00 - total_loss: 1842.0861 - val_factorized_top_k/top_1_categorical_accuracy: 0.0232 - val_factorized_top_k/top_5_categorical_accuracy: 0.0738 - val_factorized_top_k/top_10_categorical_accuracy: 0.0859 - val_factorized_top_k/top_50_categorical_accuracy: 0.1086 - val_factorized_top_k/top_100_categorical_accuracy: 0.1251 - val_loss: 63074.0000 - val_regularization_loss: 0.0000e+00 - val_total_loss: 63074.0000\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2443 - factorized_top_k/top_5_categorical_accuracy: 0.8697 - factorized_top_k/top_10_categorical_accuracy: 0.9710 - factorized_top_k/top_50_categorical_accuracy: 0.9979 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 1845.0689 - regularization_loss: 0.0000e+00 - total_loss: 1845.0689\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2413 - factorized_top_k/top_5_categorical_accuracy: 0.8693 - factorized_top_k/top_10_categorical_accuracy: 0.9707 - factorized_top_k/top_50_categorical_accuracy: 0.9978 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 1835.6328 - regularization_loss: 0.0000e+00 - total_loss: 1835.6328\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 113s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2444 - factorized_top_k/top_5_categorical_accuracy: 0.8690 - factorized_top_k/top_10_categorical_accuracy: 0.9707 - factorized_top_k/top_50_categorical_accuracy: 0.9978 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1837.2155 - regularization_loss: 0.0000e+00 - total_loss: 1837.2155\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 114s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2429 - factorized_top_k/top_5_categorical_accuracy: 0.8702 - factorized_top_k/top_10_categorical_accuracy: 0.9714 - factorized_top_k/top_50_categorical_accuracy: 0.9978 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1831.5278 - regularization_loss: 0.0000e+00 - total_loss: 1831.5278\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 141s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.2423 - factorized_top_k/top_5_categorical_accuracy: 0.8702 - factorized_top_k/top_10_categorical_accuracy: 0.9715 - factorized_top_k/top_50_categorical_accuracy: 0.9980 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 1829.9635 - regularization_loss: 0.0000e+00 - total_loss: 1829.9635 - val_factorized_top_k/top_1_categorical_accuracy: 0.0224 - val_factorized_top_k/top_5_categorical_accuracy: 0.0739 - val_factorized_top_k/top_10_categorical_accuracy: 0.0860 - val_factorized_top_k/top_50_categorical_accuracy: 0.1080 - val_factorized_top_k/top_100_categorical_accuracy: 0.1245 - val_loss: 63131.8438 - val_regularization_loss: 0.0000e+00 - val_total_loss: 63131.8438\n"
     ]
    }
   ],
   "source": [
    "model = HNMModel(use_timestamps=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model_ts = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=100)\n",
    "\n",
    "# train_accuracy = model.evaluate(\n",
    "#     cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "# test_accuracy = model.evaluate(\n",
    "#     cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "# print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "# print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eedd290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RecModel(customer_model, article_model, task)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# model.fit(trans.batch(4096), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "611caf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fac9c4715b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_validation_runs = len(model_def.history[\"val_factorized_top_k/top_10_categorical_accuracy\"])\n",
    "epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, model_def.history[\"val_factorized_top_k/top_10_categorical_accuracy\"], label=\"w/o timesteps\")\n",
    "plt.plot(epochs, model_ts.history[\"val_factorized_top_k/top_10_categorical_accuracy\"], label=\"w/ timesteps\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfacc69",
   "metadata": {},
   "source": [
    "## Get Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "239b0c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None,), types: tf.string>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b21ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca6acea4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_3021994/2158798132.py\", line 10, in None  *\n        lambda x: model.candidate_model({\n\n    TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'article_id'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m index \u001b[38;5;241m=\u001b[39m tfrs\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mfactorized_top_k\u001b[38;5;241m.\u001b[39mBruteForce(model\u001b[38;5;241m.\u001b[39mquery_model)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(articles.batch(100).map(lambda title: (title, model.candidate_model(title))))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# index.index_from_dataset(\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     articles.batch(100).map(lambda title: (title, model.candidate_model(title))))\u001b[39;00m\n\u001b[1;32m      8\u001b[0m index\u001b[38;5;241m.\u001b[39mindex_from_dataset(\n\u001b[0;32m----> 9\u001b[0m     \u001b[43marticles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprod_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprod_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# index.index(articles.batch(100).map(model.candidate_model),\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#            articles.batch(100).map(lambda x: x['article_id']))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# model.candidate_model('')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m test_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(trans_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m                         ]]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2004\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2001\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2002\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2003\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2004\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2007\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2008\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2011\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2012\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5455\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5459\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4533\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4526\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   4527\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4528\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4529\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4530\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4531\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m-> 4533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4534\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m   4535\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3244\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3236\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3237\u001b[0m \n\u001b[1;32m   3238\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3243\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3244\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3245\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3246\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3247\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3210\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3210\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3211\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3212\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3213\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3557\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3553\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3554\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3557\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3392\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3387\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3389\u001b[0m ]\n\u001b[1;32m   3390\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3391\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3392\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3393\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3394\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3395\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3400\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3401\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3404\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3405\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3406\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3409\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1143\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1143\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1148\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4510\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4504\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m   4505\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m   4506\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m   4507\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   4508\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m   4509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m-> 4510\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4511\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m   4512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4440\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m   4439\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m-> 4440\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m   4442\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:699\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    700\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_3021994/2158798132.py\", line 10, in None  *\n        lambda x: model.candidate_model({\n\n    TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'article_id'\n"
     ]
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
    "\n",
    "# print(articles.batch(100).map(lambda title: (title, model.candidate_model(title))))\n",
    "\n",
    "# index.index_from_dataset(\n",
    "#     articles.batch(100).map(lambda title: (title, model.candidate_model(title))))\n",
    "\n",
    "index.index_from_dataset(\n",
    "    articles.batch(100).map(lambda x: model.candidate_model({\n",
    "        'article_id': x['article_id'],\n",
    "        'prod_name' : x['prod_name'],\n",
    "    })))\n",
    "\n",
    "# index.index(articles.batch(100).map(model.candidate_model),\n",
    "#            articles.batch(100).map(lambda x: x['article_id']))\n",
    "\n",
    "# model.candidate_model('')\n",
    "\n",
    "test_query = dict(trans_df[['customer_id',\n",
    "                           'timestamp',\n",
    "                        ]].iloc[10].map(lambda x: tf.expand_dims(x, axis=0)))\n",
    "\n",
    "_, titles = index(test_query, k=3)\n",
    "print(f\"Top 12 recommendations for user 40: {titles[0, :20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34a22261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thomas paperbag wide'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_map[501323011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25151ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df.iloc[0].customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af93e6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id    000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...\n",
       "timestamp                                           1537401600.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df[['customer_id','timestamp']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074eb4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
